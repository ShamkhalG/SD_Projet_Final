{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6baa9f52",
   "metadata": {},
   "source": [
    "# Shamkhal Guliyev, Yigit Yumus\n",
    "# SD Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f03237-a27b-4415-aa07-b7b7b2420ec3",
   "metadata": {},
   "source": [
    "Package MTCFeatures: https://pvankranenburg.github.io/MTCFeatures/\n",
    "\n",
    "Pour récupérer les MIDI ou pdf pour que ce soit plus visuel (en particulier, c'est le dataset MTC-FS-INST (900Mb)): https://www.liederenbank.nl/mtc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86a957a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# décommenter pour installer le package une fois pour toutes\n",
    "\n",
    "# !pip install MTCFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1dbf05c-c3e4-4983-ae0f-3cb6d6fc6b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from MTCFeatures import MTCFeatureLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40ed33d1-4a7c-458b-a7d1-10899c319737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run once\n",
    "\n",
    "# import MTCFeatures\n",
    "# MTCFeatures.downloadData(dest='user')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b02d5b77-9385-49d5-9f22-b3237ebebde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fl = MTCFeatureLoader('MTC-FS-INST-2.0')\n",
    "seqs = fl.sequences()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b3c545e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "generator"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06ffd139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'NLB125814_01', 'tunefamily': '11965_0', 'year': 1884, 'tunefamily_full': 'Ach wie ist es möglich denn', 'type': 'instrumental', 'freemeter': False, 'features': {'scaledegree': [3, 1, 6, 5, 1, 1, 2, 1, 2, 3, 6, 5, 5, 4, 5, 6, 4, 3, 2, 3, 2, 5, 2, 3, 2, 1, 6, 5, 3, 4, 3, 6, 3, 2, 5, 6, 5, 5, 4, 3, 2, 6, 7, 1], 'scaledegreespecifier': ['M', 'P', 'M', 'P', 'P', 'P', 'M', 'P', 'M', 'M', 'M', 'P', 'P', 'A', 'P', 'M', 'P', 'M', 'M', 'M', 'M', 'P', 'M', 'M', 'M', 'P', 'M', 'P', 'M', 'P', 'M', 'M', 'M', 'M', 'P', 'M', 'P', 'P', 'P', 'M', 'M', 'M', 'M', 'P'], 'tonic': ['C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C'], 'mode': ['major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major', 'major'], 'metriccontour': [None, '-', '-', '+', '-', '+', '+', '-', '-', '+', '-', '+', '+', '-', '-', '+', '-', '+', '+', '-', '-', '+', '=', '-', '-', '+', '-', '+', '+', '-', '-', '+', '-', '+', '+', '-', '-', '+', '-', '+', '+', '-', '-', '+'], 'imaweight': [0.798013, 0.663907, 0.150662, 0.945364, 0.013245, 0.524834, 0.93543, 0.673841, 0.195364, 0.812914, 0.162252, 0.627483, 0.951987, 0.59106, 0.228477, 0.927152, 0.183775, 0.642384, 0.837748, 0.692053, 0.25, 1.0, 0.998344, 0.715232, 0.243377, 0.870861, 0.205298, 0.630795, 0.917219, 0.614238, 0.221854, 0.942053, 0.162252, 0.652318, 0.84106, 0.652318, 0.183775, 0.961921, 0.145695, 0.551325, 0.94702, 0.690397, 0.153974, 0.791391], 'pitch40': [135, 123, 112, 106, 123, 123, 129, 123, 129, 135, 112, 106, 106, 101, 106, 112, 140, 135, 129, 135, 129, 106, 129, 135, 129, 123, 112, 106, 135, 140, 135, 112, 135, 129, 106, 112, 106, 106, 140, 135, 129, 112, 118, 123], 'midipitch': [64, 60, 57, 55, 60, 60, 62, 60, 62, 64, 57, 55, 55, 54, 55, 57, 65, 64, 62, 64, 62, 55, 62, 64, 62, 60, 57, 55, 64, 65, 64, 57, 64, 62, 55, 57, 55, 55, 65, 64, 62, 57, 59, 60], 'diatonicpitch': [30, 28, 26, 25, 28, 28, 29, 28, 29, 30, 26, 25, 25, 24, 25, 26, 31, 30, 29, 30, 29, 25, 29, 30, 29, 28, 26, 25, 30, 31, 30, 26, 30, 29, 25, 26, 25, 25, 31, 30, 29, 26, 27, 28], 'diatonicinterval': [None, -2, -2, -1, 3, 0, 1, -1, 1, 1, -4, -1, 0, -1, 1, 1, 5, -1, -1, 1, -1, -4, 4, 1, -1, -1, -2, -1, 5, 1, -1, -4, 4, -1, -4, 1, -1, 0, 6, -1, -1, -3, 1, 1], 'chromaticinterval': [None, -4, -3, -2, 5, 0, 2, -2, 2, 2, -7, -2, 0, -1, 1, 2, 8, -1, -2, 2, -2, -7, 7, 2, -2, -2, -3, -2, 9, 1, -1, -7, 7, -2, -7, 2, -2, 0, 10, -1, -2, -5, 2, 1], 'pitchproximity': [None, None, 3, 2, 5, 0, 2, 2, 2, 2, 7, 2, 0, 1, 1, 2, 8, 1, 2, 2, 2, 7, 7, 2, 2, 2, 3, 2, 9, 1, 1, 7, 7, 2, 7, 2, 2, 0, 10, 1, 2, 5, 2, 1], 'pitchreversal': [None, None, 0, 0, 0, 0, 0, 1.5, 1.5, 0, 0, -1, 0, 0, 1.5, 0, 0, 1, 0, 1.5, 1.5, 0, 2.5, -1, 1.5, 0, 0, 0, 0, -1, 1.5, 0, 2.5, 1, 0, 1, 1.5, 0, 0, 1, 0, 0, 0, 0], 'nextisrest': [False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True], 'restduration_frac': [None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, '1', None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, '1/2'], 'duration': [1.0, 0.5, 0.5, 0.75, 0.25, 1.0, 1.0, 0.5, 0.5, 0.5, 0.5, 1.0, 1.0, 0.5, 0.5, 0.5, 0.5, 1.0, 1.0, 0.5, 0.5, 1.0, 1.0, 0.5, 0.5, 0.5, 0.5, 1.0, 1.0, 0.5, 0.5, 0.5, 0.5, 1.0, 1.0, 0.5, 0.5, 0.5, 0.5, 1.0, 1.0, 0.5, 0.5, 1.5], 'duration_frac': ['1', '1/2', '1/2', '3/4', '1/4', '1', '1', '1/2', '1/2', '1/2', '1/2', '1', '1', '1/2', '1/2', '1/2', '1/2', '1', '1', '1/2', '1/2', '1', '1', '1/2', '1/2', '1/2', '1/2', '1', '1', '1/2', '1/2', '1/2', '1/2', '1', '1', '1/2', '1/2', '1/2', '1/2', '1', '1', '1/2', '1/2', '3/2'], 'duration_fullname': ['Quarter', 'Eighth', 'Eighth', 'Dotted Eighth', '16th', 'Quarter', 'Quarter', 'Eighth', 'Eighth', 'Eighth', 'Eighth', 'Quarter', 'Quarter', 'Eighth', 'Eighth', 'Eighth', 'Eighth', 'Quarter', 'Quarter', 'Eighth', 'Eighth', 'Quarter', 'Quarter', 'Eighth', 'Eighth', 'Eighth', 'Eighth', 'Quarter', 'Quarter', 'Eighth', 'Eighth', 'Eighth', 'Eighth', 'Quarter', 'Quarter', 'Eighth', 'Eighth', 'Eighth', 'Eighth', 'Quarter', 'Quarter', 'Eighth', 'Eighth', 'Dotted Quarter'], 'onsettick': [0, 4, 6, 8, 11, 12, 16, 20, 22, 24, 26, 28, 32, 36, 38, 40, 42, 44, 48, 52, 54, 56, 64, 68, 70, 72, 74, 76, 80, 84, 86, 88, 90, 92, 96, 100, 102, 104, 106, 108, 112, 116, 118, 120], 'beatfraction': ['1', '1/2', '1/2', '3/4', '1/4', '1', '1', '1/2', '1/2', '1/2', '1/2', '1', '1', '1/2', '1/2', '1/2', '1/2', '1', '1', '1/2', '1/2', '1', '1', '1/2', '1/2', '1/2', '1/2', '1', '1', '1/2', '1/2', '1/2', '1/2', '1', '1', '1/2', '1/2', '1/2', '1/2', '1', '1', '1/2', '1/2', '3/2'], 'phrasepos': [0.0, 0.142857, 0.214286, 0.285714, 0.392857, 0.428571, 0.571429, 0.714286, 0.785714, 0.857143, 0.928571, 1.0, 0.0, 0.166667, 0.25, 0.333333, 0.416667, 0.5, 0.666667, 0.833333, 0.916667, 1.0, 0.0, 0.142857, 0.214286, 0.285714, 0.357143, 0.428571, 0.571429, 0.714286, 0.785714, 0.857143, 0.928571, 1.0, 0.0, 0.166667, 0.25, 0.333333, 0.416667, 0.5, 0.666667, 0.833333, 0.916667, 1.0], 'phrase_ix': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], 'phrase_end': [False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, True], 'songpos': [0.0, 0.03333333333333333, 0.05, 0.06666666666666667, 0.09166666666666666, 0.1, 0.13333333333333333, 0.16666666666666666, 0.18333333333333332, 0.2, 0.21666666666666667, 0.23333333333333334, 0.26666666666666666, 0.3, 0.31666666666666665, 0.3333333333333333, 0.35, 0.36666666666666664, 0.4, 0.43333333333333335, 0.45, 0.4666666666666667, 0.5333333333333333, 0.5666666666666667, 0.5833333333333334, 0.6, 0.6166666666666667, 0.6333333333333333, 0.6666666666666666, 0.7, 0.7166666666666667, 0.7333333333333333, 0.75, 0.7666666666666667, 0.8, 0.8333333333333334, 0.85, 0.8666666666666667, 0.8833333333333333, 0.9, 0.9333333333333333, 0.9666666666666667, 0.9833333333333333, 1.0], 'beatinsong': ['0', '1', '3/2', '2', '11/4', '3', '4', '5', '11/2', '6', '13/2', '7', '8', '9', '19/2', '10', '21/2', '11', '12', '13', '27/2', '14', '16', '17', '35/2', '18', '37/2', '19', '20', '21', '43/2', '22', '45/2', '23', '24', '25', '51/2', '26', '53/2', '27', '28', '29', '59/2', '30'], 'beatinphrase': ['0', '1', '3/2', '2', '11/4', '3', '4', '5', '11/2', '6', '13/2', '7', '0', '1', '3/2', '2', '5/2', '3', '4', '5', '11/2', '6', '0', '1', '3/2', '2', '5/2', '3', '4', '5', '11/2', '6', '13/2', '7', '0', '1', '3/2', '2', '5/2', '3', '4', '5', '11/2', '6'], 'beatinphrase_end': ['-6', '-5', '-9/2', '-4', '-13/4', '-3', '-2', '-1', '-1/2', '0', '1/2', '1', '-6', '-5', '-9/2', '-4', '-7/2', '-3', '-2', '-1', '-1/2', '0', '-6', '-5', '-9/2', '-4', '-7/2', '-3', '-2', '-1', '-1/2', '0', '1/2', '1', '-6', '-5', '-9/2', '-4', '-7/2', '-3', '-2', '-1', '-1/2', '0'], 'IOI_frac': ['1', '1/2', '1/2', '3/4', '1/4', '1', '1', '1/2', '1/2', '1/2', '1/2', '1', '1', '1/2', '1/2', '1/2', '1/2', '1', '1', '1/2', '1/2', '2', '1', '1/2', '1/2', '1/2', '1/2', '1', '1', '1/2', '1/2', '1/2', '1/2', '1', '1', '1/2', '1/2', '1/2', '1/2', '1', '1', '1/2', '1/2', '2'], 'IOI': [1.0, 0.5, 0.5, 0.75, 0.25, 1.0, 1.0, 0.5, 0.5, 0.5, 0.5, 1.0, 1.0, 0.5, 0.5, 0.5, 0.5, 1.0, 1.0, 0.5, 0.5, 2.0, 1.0, 0.5, 0.5, 0.5, 0.5, 1.0, 1.0, 0.5, 0.5, 0.5, 0.5, 1.0, 1.0, 0.5, 0.5, 0.5, 0.5, 1.0, 1.0, 0.5, 0.5, 2.0], 'IOR': [None, 0.5, 1.0, 1.5, 0.3333333333333333, 4.0, 1.0, 0.5, 1.0, 1.0, 1.0, 2.0, 1.0, 0.5, 1.0, 1.0, 1.0, 2.0, 1.0, 0.5, 1.0, 4.0, 0.5, 0.5, 1.0, 1.0, 1.0, 2.0, 1.0, 0.5, 1.0, 1.0, 1.0, 2.0, 1.0, 0.5, 1.0, 1.0, 1.0, 2.0, 1.0, 0.5, 1.0, 4.0], 'imacontour': [None, '-', '-', '+', '-', '+', '+', '-', '-', '+', '-', '+', '+', '-', '-', '+', '-', '+', '+', '-', '-', '+', '-', '-', '-', '+', '-', '+', '+', '-', '-', '+', '-', '+', '+', '-', '-', '+', '-', '+', '+', '-', '-', '+'], 'pitch': ['E4', 'C4', 'A3', 'G3', 'C4', 'C4', 'D4', 'C4', 'D4', 'E4', 'A3', 'G3', 'G3', 'F#3', 'G3', 'A3', 'F4', 'E4', 'D4', 'E4', 'D4', 'G3', 'D4', 'E4', 'D4', 'C4', 'A3', 'G3', 'E4', 'F4', 'E4', 'A3', 'E4', 'D4', 'G3', 'A3', 'G3', 'G3', 'F4', 'E4', 'D4', 'A3', 'B3', 'C4'], 'contour3': [None, '-', '-', '-', '+', '=', '+', '-', '+', '+', '-', '-', '=', '-', '+', '+', '+', '-', '-', '+', '-', '-', '+', '+', '-', '-', '-', '-', '+', '+', '-', '-', '+', '-', '-', '+', '-', '=', '+', '-', '-', '-', '+', '+'], 'contour5': [None, '--', '--', '-', '++', '=', '+', '-', '+', '+', '--', '-', '=', '-', '+', '+', '++', '-', '-', '+', '-', '--', '++', '+', '-', '-', '--', '-', '++', '+', '-', '--', '++', '-', '--', '+', '-', '=', '++', '-', '-', '--', '+', '+'], 'beatstrength': [1.0, 0.5, 0.25, 1.0, 0.125, 0.5, 1.0, 0.5, 0.25, 1.0, 0.25, 0.5, 1.0, 0.5, 0.25, 1.0, 0.25, 0.5, 1.0, 0.5, 0.25, 1.0, 1.0, 0.5, 0.25, 1.0, 0.25, 0.5, 1.0, 0.5, 0.25, 1.0, 0.25, 0.5, 1.0, 0.5, 0.25, 1.0, 0.25, 0.5, 1.0, 0.5, 0.25, 1.0], 'beat_str': ['1', '2', '2', '1', '1', '2', '1', '2', '2', '1', '1', '2', '1', '2', '2', '1', '1', '2', '1', '2', '2', '1', '1', '2', '2', '1', '1', '2', '1', '2', '2', '1', '1', '2', '1', '2', '2', '1', '1', '2', '1', '2', '2', '1'], 'beat_fraction_str': ['0', '0', '1/2', '0', '3/4', '0', '0', '0', '1/2', '0', '1/2', '0', '0', '0', '1/2', '0', '1/2', '0', '0', '0', '1/2', '0', '0', '0', '1/2', '0', '1/2', '0', '0', '0', '1/2', '0', '1/2', '0', '0', '0', '1/2', '0', '1/2', '0', '0', '0', '1/2', '0'], 'beat': [1.0, 2.0, 2.5, 1.0, 1.75, 2.0, 1.0, 2.0, 2.5, 1.0, 1.5, 2.0, 1.0, 2.0, 2.5, 1.0, 1.5, 2.0, 1.0, 2.0, 2.5, 1.0, 1.0, 2.0, 2.5, 1.0, 1.5, 2.0, 1.0, 2.0, 2.5, 1.0, 1.5, 2.0, 1.0, 2.0, 2.5, 1.0, 1.5, 2.0, 1.0, 2.0, 2.5, 1.0], 'timesignature': ['2/4', '2/4', '2/4', '2/4', '2/4', '2/4', '2/4', '2/4', '2/4', '2/4', '2/4', '2/4', '2/4', '2/4', '2/4', '2/4', '2/4', '2/4', '2/4', '2/4', '2/4', '2/4', '2/4', '2/4', '2/4', '2/4', '2/4', '2/4', '2/4', '2/4', '2/4', '2/4', '2/4', '2/4', '2/4', '2/4', '2/4', '2/4', '2/4', '2/4', '2/4', '2/4', '2/4', '2/4'], 'gpr2a_Frankland': [None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, 0.25, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, 0.125], 'gpr2b_Frankland': [None, None, None, 0.5, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None], 'gpr3a_Frankland': [None, None, None, 0.8, None, None, None, None, None, 0.7142857142857143, None, None, None, None, None, 0.8125, None, None, None, None, None, None, None, None, None, 0.33333333333333337, None, 0.8333333333333334, None, None, None, None, None, 0.7142857142857143, None, None, None, 0.95, None, None, 0.6, None, None, None], 'gpr3d_Frankland': [None, None, None, None, None, None, 0.5, None, 0.0, None, 0.5, None, 0.5, None, 0.0, None, 0.5, None, 0.5, None, None, None, None, None, 0.0, None, 0.5, None, 0.5, None, 0.0, None, 0.5, None, 0.5, None, 0.0, None, 0.5, None, 0.5, None, None, None], 'gpr_Frankland_sum': [0, 0, 0, 1.3, 0, 0, 0.5, 0, 0, 0.7142857142857143, 0.5, 0, 0.5, 0, 0, 0.8125, 0.5, 0, 0.5, 0, 0, 0.25, 0, 0, 0, 0.33333333333333337, 0.5, 0.8333333333333334, 0.5, 0, 0, 0, 0.5, 0.7142857142857143, 0.5, 0, 0, 0.95, 0.5, 0, 1.1, 0, 0, 0.125], 'lbdm_spitch': [None, 0.04993997599039616, 0.062424969987995196, 0.3433373349339736, 0.0, 0.06554621848739496, 0.0, 0.0, 0.059587471352177235, 0.41711229946524064, 0.1251336898395722, 0.0, 0.021848739495798318, 0.013109243697478993, 0.09176470588235294, 0.5958747135217723, 0.05482047364400306, 0.026218487394957985, 0.0, 0.059587471352177235, 0.20855614973262032, 0.20855614973262032, 0.059587471352177235, 0.0, 0.01872749099639856, 0.05618247298919568, 0.08931572629051622, 0.7109243697478991, 0.043697478991596636, 0.03932773109243697, 0.27529411764705886, 0.20855614973262032, 0.11917494270435447, 0.41711229946524064, 0.059587471352177235, 0.06554621848739496, 0.0, 1.0, 0.05848739495798319, 0.06991596638655463, 0.2184873949579832, 0.06991596638655463, None, None], 'lbdm_sioi': [None, 0.08928571428571427, 0.053571428571428575, 0.28124999999999994, 0.14732142857142858, 0.3214285714285714, 0.17857142857142855, 0.08928571428571427, 0.0, 0.0, 0.08928571428571427, 0.17857142857142855, 0.17857142857142855, 0.08928571428571427, 0.0, 0.0, 0.08928571428571427, 0.17857142857142855, 0.17857142857142855, 0.08928571428571427, 0.1607142857142857, 1.0, 0.3571428571428571, 0.08928571428571427, 0.0, 0.0, 0.08928571428571427, 0.17857142857142855, 0.17857142857142855, 0.08928571428571427, 0.0, 0.0, 0.08928571428571427, 0.17857142857142855, 0.17857142857142855, 0.08928571428571427, 0.0, 0.0, 0.08928571428571427, 0.17857142857142855, 0.17857142857142855, 0.08928571428571427, None, None], 'lbdm_srest': [None, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, None, None], 'lbdm_rpitch': [None, 0.1111111111111111, 0.14285714285714285, 0.3333333333333333, 0.7142857142857143, 0.5, 0.0, 0.0, 0.0, 0.45454545454545453, 0.45454545454545453, 0.5, 0.3333333333333333, 0.0, 0.2, 0.5, 0.6363636363636364, 0.2, 0.0, 0.0, 0.45454545454545453, 0.0, 0.45454545454545453, 0.0, 0.0, 0.14285714285714285, 0.14285714285714285, 0.5384615384615384, 0.6666666666666666, 0.0, 0.6, 0.0, 0.45454545454545453, 0.45454545454545453, 0.45454545454545453, 0.0, 0.5, 0.8333333333333334, 0.6923076923076923, 0.2, 0.3333333333333333, 0.3333333333333333, 0.2, None], 'lbdm_rioi': [None, 0.3333333333333333, 0.0, 0.2, 0.5, 0.6, 0.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.3333333333333333, 0.0, 0.6, 0.3333333333333333, 0.3333333333333333, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.3333333333333333, 0.0, None], 'lbdm_rrest': [None, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, None], 'lbdm_boundarystrength': [None, 0.057127851140456175, 0.04239195678271308, 0.22645933373349336, 0.07366071428571429, 0.17710084033613444, 0.08928571428571427, 0.04464285714285714, 0.014896867838044309, 0.10427807486631016, 0.0759262796027502, 0.08928571428571427, 0.09474789915966385, 0.04792016806722688, 0.022941176470588236, 0.1489686783804431, 0.0583479755538579, 0.09584033613445377, 0.08928571428571427, 0.059539724980901446, 0.13249618029029792, 0.8021390374331551, 0.19346829640947286, 0.04464285714285714, 0.00468187274909964, 0.01404561824729892, 0.06697178871548619, 0.267016806722689, 0.10021008403361344, 0.05447478991596638, 0.06882352941176471, 0.05213903743315508, 0.07443659281894575, 0.19356378915202443, 0.10418258212375858, 0.061029411764705874, 0.0, 0.25, 0.059264705882352935, 0.10676470588235293, 0.14390756302521007, 0.06212184873949579, None, None], 'durationcontour': [None, '-', '=', '+', '-', '+', '=', '-', '=', '=', '=', '+', '=', '-', '=', '=', '=', '+', '=', '-', '=', '+', '=', '-', '=', '=', '=', '+', '=', '-', '=', '=', '=', '+', '=', '-', '=', '=', '=', '+', '=', '-', '=', '+'], 'IOR_frac': [None, '1/2', '1', '3/2', '1/3', '4', '1', '1/2', '1', '1', '1', '2', '1', '1/2', '1', '1', '1', '2', '1', '1/2', '1', '4', '1/2', '1/2', '1', '1', '1', '2', '1', '1/2', '1', '1', '1', '2', '1', '1/2', '1', '1', '1', '2', '1', '1/2', '1', '4']}, 'ann_bgcorpus': True}\n",
      "dict_keys(['id', 'tunefamily', 'year', 'tunefamily_full', 'type', 'freemeter', 'features', 'ann_bgcorpus'])\n",
      "dict_keys(['scaledegree', 'scaledegreespecifier', 'tonic', 'mode', 'metriccontour', 'imaweight', 'pitch40', 'midipitch', 'diatonicpitch', 'diatonicinterval', 'chromaticinterval', 'pitchproximity', 'pitchreversal', 'nextisrest', 'restduration_frac', 'duration', 'duration_frac', 'duration_fullname', 'onsettick', 'beatfraction', 'phrasepos', 'phrase_ix', 'phrase_end', 'songpos', 'beatinsong', 'beatinphrase', 'beatinphrase_end', 'IOI_frac', 'IOI', 'IOR', 'imacontour', 'pitch', 'contour3', 'contour5', 'beatstrength', 'beat_str', 'beat_fraction_str', 'beat', 'timesignature', 'gpr2a_Frankland', 'gpr2b_Frankland', 'gpr3a_Frankland', 'gpr3d_Frankland', 'gpr_Frankland_sum', 'lbdm_spitch', 'lbdm_sioi', 'lbdm_srest', 'lbdm_rpitch', 'lbdm_rioi', 'lbdm_rrest', 'lbdm_boundarystrength', 'durationcontour', 'IOR_frac'])\n"
     ]
    }
   ],
   "source": [
    "item = seqs.__next__()\n",
    "print(item)\n",
    "print(item.keys())\n",
    "print(item['features'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16cc1133-8aef-4784-8575-92e2a85edf27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.02 s, sys: 226 ms, total: 7.25 s\n",
      "Wall time: 7.26 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "phrase_data = []\n",
    "for ii, x in enumerate(seqs):\n",
    "    phrase_data.append({\n",
    "        'id': x['id'],\n",
    "        **x['features']\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89588982-6256-4339-b77e-e07a0114752e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>scaledegree</th>\n",
       "      <th>scaledegreespecifier</th>\n",
       "      <th>tonic</th>\n",
       "      <th>mode</th>\n",
       "      <th>metriccontour</th>\n",
       "      <th>imaweight</th>\n",
       "      <th>pitch40</th>\n",
       "      <th>midipitch</th>\n",
       "      <th>diatonicpitch</th>\n",
       "      <th>...</th>\n",
       "      <th>durationcontour</th>\n",
       "      <th>IOR_frac</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>noncontentword</th>\n",
       "      <th>wordend</th>\n",
       "      <th>phoneme</th>\n",
       "      <th>rhymes</th>\n",
       "      <th>rhymescontentwords</th>\n",
       "      <th>wordstress</th>\n",
       "      <th>melismastate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NLB125815_01</td>\n",
       "      <td>[5, 5, 6, 5, 4, 3, 1, 3, 3, 3, 3, 6, 5, 5, 6, ...</td>\n",
       "      <td>[P, A, M, P, P, M, P, M, M, M, M, M, P, P, M, ...</td>\n",
       "      <td>[F, F, F, F, F, F, F, F, F, F, F, F, F, F, F, ...</td>\n",
       "      <td>[major, major, major, major, major, major, maj...</td>\n",
       "      <td>[None, -, +, -, +, -, +, -, -, +, -, +, +, -, ...</td>\n",
       "      <td>[0.236646, 0.015528, 0.913043, 0.204348, 0.392...</td>\n",
       "      <td>[163, 164, 169, 163, 157, 152, 140, 152, 152, ...</td>\n",
       "      <td>[72, 73, 74, 72, 70, 69, 65, 69, 69, 69, 69, 7...</td>\n",
       "      <td>[32, 32, 33, 32, 31, 30, 28, 30, 30, 30, 30, 3...</td>\n",
       "      <td>...</td>\n",
       "      <td>[None, -, +, =, =, =, -, -, =, +, =, +, -, -, ...</td>\n",
       "      <td>[None, 1/3, 4, 1, 1, 1, 1/2, 1/2, 1, 2, 1, 4, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NLB125817_01</td>\n",
       "      <td>[5, 5, 5, 1, 5, 3, 2, 5, 2, 3, 2, 1, 2, 3, 4, ...</td>\n",
       "      <td>[P, P, P, P, P, M, M, P, M, M, M, P, M, M, P, ...</td>\n",
       "      <td>[C, C, C, C, C, C, C, C, C, C, C, C, C, C, C, ...</td>\n",
       "      <td>[major, major, major, major, major, major, maj...</td>\n",
       "      <td>[None, +, -, +, -, +, -, +, -, +, -, +, -, +, ...</td>\n",
       "      <td>[0.246883, 0.306733, 0.169576, 0.780549, 0.349...</td>\n",
       "      <td>[146, 146, 146, 163, 146, 175, 169, 146, 169, ...</td>\n",
       "      <td>[67, 67, 67, 72, 67, 76, 74, 67, 74, 76, 74, 7...</td>\n",
       "      <td>[32, 32, 32, 35, 32, 37, 36, 32, 36, 37, 36, 3...</td>\n",
       "      <td>...</td>\n",
       "      <td>[None, =, =, +, -, +, -, +, -, +, -, =, =, =, ...</td>\n",
       "      <td>[None, 1, 1, 3, 1/3, 3, 1/3, 6, 1/3, 3/2, 1/3,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NLB125818_01</td>\n",
       "      <td>[1, 1, 1, 1, 3, 2, 1, 7, 2, 2, 5, 4, 3, 4, 3, ...</td>\n",
       "      <td>[P, P, P, P, m, M, P, m, M, M, P, P, m, P, m, ...</td>\n",
       "      <td>[C, C, C, C, C, C, C, C, C, C, C, C, C, C, C, ...</td>\n",
       "      <td>[minor, minor, minor, minor, minor, minor, min...</td>\n",
       "      <td>[None, +, -, +, +, -, -, +, -, -, +, -, +, -, ...</td>\n",
       "      <td>[0.080378, 0.617021, 0.202128, 0.361702, 0.320...</td>\n",
       "      <td>[163, 163, 163, 163, 174, 169, 163, 157, 169, ...</td>\n",
       "      <td>[72, 72, 72, 72, 75, 74, 72, 70, 74, 74, 79, 7...</td>\n",
       "      <td>[35, 35, 35, 35, 37, 36, 35, 34, 36, 36, 39, 3...</td>\n",
       "      <td>...</td>\n",
       "      <td>[None, =, =, +, =, -, =, +, -, =, +, -, +, -, ...</td>\n",
       "      <td>[None, 1, 1, 2, 1, 1/2, 1, 2, 1/2, 1, 3, 1/3, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NLB125822_01</td>\n",
       "      <td>[5, 5, 5, 5, 5, 5, 5, 3, 3, 3, 3, 3, 3, 3, 3, ...</td>\n",
       "      <td>[P, P, P, P, P, P, P, M, M, M, M, M, M, M, M, ...</td>\n",
       "      <td>[F, F, F, F, F, F, F, F, F, F, F, F, F, F, F, ...</td>\n",
       "      <td>[major, major, major, major, major, major, maj...</td>\n",
       "      <td>[None, -, -, +, -, -, +, -, +, +, -, -, +, -, ...</td>\n",
       "      <td>[0.971634, 0.069592, 0.005484, 0.783094, 0.071...</td>\n",
       "      <td>[163, 163, 163, 163, 163, 163, 163, 152, 152, ...</td>\n",
       "      <td>[72, 72, 72, 72, 72, 72, 72, 69, 69, 69, 69, 6...</td>\n",
       "      <td>[32, 32, 32, 32, 32, 32, 32, 30, 30, 30, 30, 3...</td>\n",
       "      <td>...</td>\n",
       "      <td>[None, -, =, +, -, =, +, =, +, -, -, =, +, -, ...</td>\n",
       "      <td>[None, 1/2, 1, 2, 1/2, 1, 2, 1, 2, 1/2, 1/2, 1...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NLB125823_01</td>\n",
       "      <td>[3, 4, 4, 4, 5, 1, 1, 1, 2, 1, 2, 3, 4, 3, 2, ...</td>\n",
       "      <td>[M, P, P, P, P, P, P, P, M, P, M, M, P, M, M, ...</td>\n",
       "      <td>[G, G, G, G, G, G, G, G, G, G, G, G, G, G, G, ...</td>\n",
       "      <td>[major, major, major, major, major, major, maj...</td>\n",
       "      <td>[None, -, -, =, +, -, +, -, +, -, +, +, -, =, ...</td>\n",
       "      <td>[0.779032, 0.627419, 0.214516, 0.133871, 0.906...</td>\n",
       "      <td>[158, 163, 163, 163, 169, 186, 146, 146, 152, ...</td>\n",
       "      <td>[71, 72, 72, 72, 74, 79, 67, 67, 69, 67, 69, 7...</td>\n",
       "      <td>[30, 31, 31, 31, 32, 35, 28, 28, 29, 28, 29, 3...</td>\n",
       "      <td>...</td>\n",
       "      <td>[None, -, =, =, +, =, -, -, +, -, +, =, =, =, ...</td>\n",
       "      <td>[None, 1/3, 1, 1, 3, 1, 2/3, 1/2, 3/2, 1/3, 2,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18103</th>\n",
       "      <td>NLB179585_01</td>\n",
       "      <td>[5, 3, 5, 3, 1, 1, 1, 2, 4, 7, 2, 1, 7, 1, 2, ...</td>\n",
       "      <td>[P, M, P, M, P, P, P, M, P, M, M, P, M, P, M, ...</td>\n",
       "      <td>[B-, B-, B-, B-, B-, B-, B-, B-, B-, B-, B-, B...</td>\n",
       "      <td>[major, major, major, major, major, major, maj...</td>\n",
       "      <td>[None, -, +, -, +, -, +, +, -, +, -, +, -, +, ...</td>\n",
       "      <td>[0.913915, 0.194076, 0.253625, 0.138537, 0.914...</td>\n",
       "      <td>[180, 169, 180, 169, 157, 157, 157, 163, 174, ...</td>\n",
       "      <td>[77, 74, 77, 74, 70, 70, 70, 72, 75, 69, 72, 7...</td>\n",
       "      <td>[32, 30, 32, 30, 28, 28, 28, 29, 31, 27, 29, 2...</td>\n",
       "      <td>...</td>\n",
       "      <td>[None, =, =, =, =, =, +, -, =, =, =, -, =, =, ...</td>\n",
       "      <td>[None, 1, 1, 1, 1, 1, 2, 1/2, 1, 1, 1, 1/2, 1,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18104</th>\n",
       "      <td>NLB179586_01</td>\n",
       "      <td>[5, 6, 5, 1, 5, 6, 5, 2, 5, 6, 5, 3, 1, 1, 2, ...</td>\n",
       "      <td>[P, M, P, P, P, M, P, M, P, M, P, M, P, A, M, ...</td>\n",
       "      <td>[F, F, F, F, F, F, F, F, F, F, F, F, F, F, F, ...</td>\n",
       "      <td>[major, major, major, major, major, major, maj...</td>\n",
       "      <td>[None, -, =, +, +, -, =, +, +, -, =, +, -, +, ...</td>\n",
       "      <td>[0.207143, 0.11, 0.234286, 0.179429, 0.233714,...</td>\n",
       "      <td>[163, 169, 163, 180, 163, 169, 163, 186, 163, ...</td>\n",
       "      <td>[72, 74, 72, 77, 72, 74, 72, 79, 72, 74, 72, 8...</td>\n",
       "      <td>[32, 33, 32, 35, 32, 33, 32, 36, 32, 33, 32, 3...</td>\n",
       "      <td>...</td>\n",
       "      <td>[None, =, =, +, -, =, =, +, -, =, =, +, -, =, ...</td>\n",
       "      <td>[None, 1, 1, 3, 1/3, 1, 1, 3, 1/3, 1, 1, 2, 1/...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18105</th>\n",
       "      <td>NLB179588_01</td>\n",
       "      <td>[1, 1, 3, 4, 5, 5, 4, 5, 1, 1, 1, 3, 4, 5, 1, ...</td>\n",
       "      <td>[P, P, M, P, P, P, A, P, P, P, P, M, P, P, P, ...</td>\n",
       "      <td>[C, C, C, C, C, C, C, C, C, C, C, C, C, C, C, ...</td>\n",
       "      <td>[major, major, major, major, major, major, maj...</td>\n",
       "      <td>[None, -, +, -, +, -, -, +, -, +, -, +, -, +, ...</td>\n",
       "      <td>[0.926503, 0.238307, 0.988122, 0.218263, 0.919...</td>\n",
       "      <td>[163, 163, 175, 180, 186, 186, 181, 186, 203, ...</td>\n",
       "      <td>[72, 72, 76, 77, 79, 79, 78, 79, 84, 72, 72, 7...</td>\n",
       "      <td>[35, 35, 37, 38, 39, 39, 38, 39, 42, 35, 35, 3...</td>\n",
       "      <td>...</td>\n",
       "      <td>[None, =, =, =, =, -, =, +, =, =, =, =, =, +, ...</td>\n",
       "      <td>[None, 1, 1, 1, 1, 1/2, 1, 2, 1, 1, 1, 1, 1, 2...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18106</th>\n",
       "      <td>NLB179589_01</td>\n",
       "      <td>[1, 5, 3, 5, 4, 6, 5, 4, 3, 1, 3, 5, 4, 6, 5, ...</td>\n",
       "      <td>[P, P, M, P, P, M, P, P, M, P, M, P, P, M, P, ...</td>\n",
       "      <td>[D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, ...</td>\n",
       "      <td>[major, major, major, major, major, major, maj...</td>\n",
       "      <td>[None, -, +, -, +, -, +, -, +, -, +, -, +, -, ...</td>\n",
       "      <td>[1.0, 0.14308, 1.0, 0.159729, 1.0, 0.192508, 1...</td>\n",
       "      <td>[169, 152, 141, 152, 146, 158, 152, 146, 141, ...</td>\n",
       "      <td>[74, 69, 66, 69, 67, 71, 69, 67, 66, 62, 66, 6...</td>\n",
       "      <td>[35, 32, 30, 32, 31, 33, 32, 31, 30, 28, 30, 3...</td>\n",
       "      <td>...</td>\n",
       "      <td>[None, -, +, -, +, -, +, -, +, -, +, -, +, -, ...</td>\n",
       "      <td>[None, 1/3, 3, 1/3, 3, 1/3, 3, 1/3, 3, 1/3, 3,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18107</th>\n",
       "      <td>NLB179590_01</td>\n",
       "      <td>[5, 5, 6, 5, 1, 5, 5, 6, 5, 3, 1, 2, 2, 2, 3, ...</td>\n",
       "      <td>[P, P, M, P, P, P, P, M, P, M, P, M, M, M, M, ...</td>\n",
       "      <td>[G, G, G, G, G, G, G, G, G, G, G, G, G, G, G, ...</td>\n",
       "      <td>[major, major, major, major, major, major, maj...</td>\n",
       "      <td>[None, +, -, =, +, -, +, -, =, +, -, +, -, +, ...</td>\n",
       "      <td>[0.371277, 0.867021, 0.188298, 0.146809, 0.914...</td>\n",
       "      <td>[169, 169, 175, 169, 186, 169, 169, 175, 169, ...</td>\n",
       "      <td>[74, 74, 76, 74, 79, 74, 74, 76, 74, 71, 67, 6...</td>\n",
       "      <td>[32, 32, 33, 32, 35, 32, 32, 33, 32, 30, 28, 2...</td>\n",
       "      <td>...</td>\n",
       "      <td>[None, =, =, =, +, -, =, =, =, +, -, +, -, =, ...</td>\n",
       "      <td>[None, 1, 1, 1, 2, 1/2, 1, 1, 1, 2, 1/2, 2, 1/...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18108 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                        scaledegree  \\\n",
       "0      NLB125815_01  [5, 5, 6, 5, 4, 3, 1, 3, 3, 3, 3, 6, 5, 5, 6, ...   \n",
       "1      NLB125817_01  [5, 5, 5, 1, 5, 3, 2, 5, 2, 3, 2, 1, 2, 3, 4, ...   \n",
       "2      NLB125818_01  [1, 1, 1, 1, 3, 2, 1, 7, 2, 2, 5, 4, 3, 4, 3, ...   \n",
       "3      NLB125822_01  [5, 5, 5, 5, 5, 5, 5, 3, 3, 3, 3, 3, 3, 3, 3, ...   \n",
       "4      NLB125823_01  [3, 4, 4, 4, 5, 1, 1, 1, 2, 1, 2, 3, 4, 3, 2, ...   \n",
       "...             ...                                                ...   \n",
       "18103  NLB179585_01  [5, 3, 5, 3, 1, 1, 1, 2, 4, 7, 2, 1, 7, 1, 2, ...   \n",
       "18104  NLB179586_01  [5, 6, 5, 1, 5, 6, 5, 2, 5, 6, 5, 3, 1, 1, 2, ...   \n",
       "18105  NLB179588_01  [1, 1, 3, 4, 5, 5, 4, 5, 1, 1, 1, 3, 4, 5, 1, ...   \n",
       "18106  NLB179589_01  [1, 5, 3, 5, 4, 6, 5, 4, 3, 1, 3, 5, 4, 6, 5, ...   \n",
       "18107  NLB179590_01  [5, 5, 6, 5, 1, 5, 5, 6, 5, 3, 1, 2, 2, 2, 3, ...   \n",
       "\n",
       "                                    scaledegreespecifier  \\\n",
       "0      [P, A, M, P, P, M, P, M, M, M, M, M, P, P, M, ...   \n",
       "1      [P, P, P, P, P, M, M, P, M, M, M, P, M, M, P, ...   \n",
       "2      [P, P, P, P, m, M, P, m, M, M, P, P, m, P, m, ...   \n",
       "3      [P, P, P, P, P, P, P, M, M, M, M, M, M, M, M, ...   \n",
       "4      [M, P, P, P, P, P, P, P, M, P, M, M, P, M, M, ...   \n",
       "...                                                  ...   \n",
       "18103  [P, M, P, M, P, P, P, M, P, M, M, P, M, P, M, ...   \n",
       "18104  [P, M, P, P, P, M, P, M, P, M, P, M, P, A, M, ...   \n",
       "18105  [P, P, M, P, P, P, A, P, P, P, P, M, P, P, P, ...   \n",
       "18106  [P, P, M, P, P, M, P, P, M, P, M, P, P, M, P, ...   \n",
       "18107  [P, P, M, P, P, P, P, M, P, M, P, M, M, M, M, ...   \n",
       "\n",
       "                                                   tonic  \\\n",
       "0      [F, F, F, F, F, F, F, F, F, F, F, F, F, F, F, ...   \n",
       "1      [C, C, C, C, C, C, C, C, C, C, C, C, C, C, C, ...   \n",
       "2      [C, C, C, C, C, C, C, C, C, C, C, C, C, C, C, ...   \n",
       "3      [F, F, F, F, F, F, F, F, F, F, F, F, F, F, F, ...   \n",
       "4      [G, G, G, G, G, G, G, G, G, G, G, G, G, G, G, ...   \n",
       "...                                                  ...   \n",
       "18103  [B-, B-, B-, B-, B-, B-, B-, B-, B-, B-, B-, B...   \n",
       "18104  [F, F, F, F, F, F, F, F, F, F, F, F, F, F, F, ...   \n",
       "18105  [C, C, C, C, C, C, C, C, C, C, C, C, C, C, C, ...   \n",
       "18106  [D, D, D, D, D, D, D, D, D, D, D, D, D, D, D, ...   \n",
       "18107  [G, G, G, G, G, G, G, G, G, G, G, G, G, G, G, ...   \n",
       "\n",
       "                                                    mode  \\\n",
       "0      [major, major, major, major, major, major, maj...   \n",
       "1      [major, major, major, major, major, major, maj...   \n",
       "2      [minor, minor, minor, minor, minor, minor, min...   \n",
       "3      [major, major, major, major, major, major, maj...   \n",
       "4      [major, major, major, major, major, major, maj...   \n",
       "...                                                  ...   \n",
       "18103  [major, major, major, major, major, major, maj...   \n",
       "18104  [major, major, major, major, major, major, maj...   \n",
       "18105  [major, major, major, major, major, major, maj...   \n",
       "18106  [major, major, major, major, major, major, maj...   \n",
       "18107  [major, major, major, major, major, major, maj...   \n",
       "\n",
       "                                           metriccontour  \\\n",
       "0      [None, -, +, -, +, -, +, -, -, +, -, +, +, -, ...   \n",
       "1      [None, +, -, +, -, +, -, +, -, +, -, +, -, +, ...   \n",
       "2      [None, +, -, +, +, -, -, +, -, -, +, -, +, -, ...   \n",
       "3      [None, -, -, +, -, -, +, -, +, +, -, -, +, -, ...   \n",
       "4      [None, -, -, =, +, -, +, -, +, -, +, +, -, =, ...   \n",
       "...                                                  ...   \n",
       "18103  [None, -, +, -, +, -, +, +, -, +, -, +, -, +, ...   \n",
       "18104  [None, -, =, +, +, -, =, +, +, -, =, +, -, +, ...   \n",
       "18105  [None, -, +, -, +, -, -, +, -, +, -, +, -, +, ...   \n",
       "18106  [None, -, +, -, +, -, +, -, +, -, +, -, +, -, ...   \n",
       "18107  [None, +, -, =, +, -, +, -, =, +, -, +, -, +, ...   \n",
       "\n",
       "                                               imaweight  \\\n",
       "0      [0.236646, 0.015528, 0.913043, 0.204348, 0.392...   \n",
       "1      [0.246883, 0.306733, 0.169576, 0.780549, 0.349...   \n",
       "2      [0.080378, 0.617021, 0.202128, 0.361702, 0.320...   \n",
       "3      [0.971634, 0.069592, 0.005484, 0.783094, 0.071...   \n",
       "4      [0.779032, 0.627419, 0.214516, 0.133871, 0.906...   \n",
       "...                                                  ...   \n",
       "18103  [0.913915, 0.194076, 0.253625, 0.138537, 0.914...   \n",
       "18104  [0.207143, 0.11, 0.234286, 0.179429, 0.233714,...   \n",
       "18105  [0.926503, 0.238307, 0.988122, 0.218263, 0.919...   \n",
       "18106  [1.0, 0.14308, 1.0, 0.159729, 1.0, 0.192508, 1...   \n",
       "18107  [0.371277, 0.867021, 0.188298, 0.146809, 0.914...   \n",
       "\n",
       "                                                 pitch40  \\\n",
       "0      [163, 164, 169, 163, 157, 152, 140, 152, 152, ...   \n",
       "1      [146, 146, 146, 163, 146, 175, 169, 146, 169, ...   \n",
       "2      [163, 163, 163, 163, 174, 169, 163, 157, 169, ...   \n",
       "3      [163, 163, 163, 163, 163, 163, 163, 152, 152, ...   \n",
       "4      [158, 163, 163, 163, 169, 186, 146, 146, 152, ...   \n",
       "...                                                  ...   \n",
       "18103  [180, 169, 180, 169, 157, 157, 157, 163, 174, ...   \n",
       "18104  [163, 169, 163, 180, 163, 169, 163, 186, 163, ...   \n",
       "18105  [163, 163, 175, 180, 186, 186, 181, 186, 203, ...   \n",
       "18106  [169, 152, 141, 152, 146, 158, 152, 146, 141, ...   \n",
       "18107  [169, 169, 175, 169, 186, 169, 169, 175, 169, ...   \n",
       "\n",
       "                                               midipitch  \\\n",
       "0      [72, 73, 74, 72, 70, 69, 65, 69, 69, 69, 69, 7...   \n",
       "1      [67, 67, 67, 72, 67, 76, 74, 67, 74, 76, 74, 7...   \n",
       "2      [72, 72, 72, 72, 75, 74, 72, 70, 74, 74, 79, 7...   \n",
       "3      [72, 72, 72, 72, 72, 72, 72, 69, 69, 69, 69, 6...   \n",
       "4      [71, 72, 72, 72, 74, 79, 67, 67, 69, 67, 69, 7...   \n",
       "...                                                  ...   \n",
       "18103  [77, 74, 77, 74, 70, 70, 70, 72, 75, 69, 72, 7...   \n",
       "18104  [72, 74, 72, 77, 72, 74, 72, 79, 72, 74, 72, 8...   \n",
       "18105  [72, 72, 76, 77, 79, 79, 78, 79, 84, 72, 72, 7...   \n",
       "18106  [74, 69, 66, 69, 67, 71, 69, 67, 66, 62, 66, 6...   \n",
       "18107  [74, 74, 76, 74, 79, 74, 74, 76, 74, 71, 67, 6...   \n",
       "\n",
       "                                           diatonicpitch  ...  \\\n",
       "0      [32, 32, 33, 32, 31, 30, 28, 30, 30, 30, 30, 3...  ...   \n",
       "1      [32, 32, 32, 35, 32, 37, 36, 32, 36, 37, 36, 3...  ...   \n",
       "2      [35, 35, 35, 35, 37, 36, 35, 34, 36, 36, 39, 3...  ...   \n",
       "3      [32, 32, 32, 32, 32, 32, 32, 30, 30, 30, 30, 3...  ...   \n",
       "4      [30, 31, 31, 31, 32, 35, 28, 28, 29, 28, 29, 3...  ...   \n",
       "...                                                  ...  ...   \n",
       "18103  [32, 30, 32, 30, 28, 28, 28, 29, 31, 27, 29, 2...  ...   \n",
       "18104  [32, 33, 32, 35, 32, 33, 32, 36, 32, 33, 32, 3...  ...   \n",
       "18105  [35, 35, 37, 38, 39, 39, 38, 39, 42, 35, 35, 3...  ...   \n",
       "18106  [35, 32, 30, 32, 31, 33, 32, 31, 30, 28, 30, 3...  ...   \n",
       "18107  [32, 32, 33, 32, 35, 32, 32, 33, 32, 30, 28, 2...  ...   \n",
       "\n",
       "                                         durationcontour  \\\n",
       "0      [None, -, +, =, =, =, -, -, =, +, =, +, -, -, ...   \n",
       "1      [None, =, =, +, -, +, -, +, -, +, -, =, =, =, ...   \n",
       "2      [None, =, =, +, =, -, =, +, -, =, +, -, +, -, ...   \n",
       "3      [None, -, =, +, -, =, +, =, +, -, -, =, +, -, ...   \n",
       "4      [None, -, =, =, +, =, -, -, +, -, +, =, =, =, ...   \n",
       "...                                                  ...   \n",
       "18103  [None, =, =, =, =, =, +, -, =, =, =, -, =, =, ...   \n",
       "18104  [None, =, =, +, -, =, =, +, -, =, =, +, -, =, ...   \n",
       "18105  [None, =, =, =, =, -, =, +, =, =, =, =, =, +, ...   \n",
       "18106  [None, -, +, -, +, -, +, -, +, -, +, -, +, -, ...   \n",
       "18107  [None, =, =, =, +, -, =, =, =, +, -, +, -, =, ...   \n",
       "\n",
       "                                                IOR_frac lyrics  \\\n",
       "0      [None, 1/3, 4, 1, 1, 1, 1/2, 1/2, 1, 2, 1, 4, ...    NaN   \n",
       "1      [None, 1, 1, 3, 1/3, 3, 1/3, 6, 1/3, 3/2, 1/3,...    NaN   \n",
       "2      [None, 1, 1, 2, 1, 1/2, 1, 2, 1/2, 1, 3, 1/3, ...    NaN   \n",
       "3      [None, 1/2, 1, 2, 1/2, 1, 2, 1, 2, 1/2, 1/2, 1...    NaN   \n",
       "4      [None, 1/3, 1, 1, 3, 1, 2/3, 1/2, 3/2, 1/3, 2,...    NaN   \n",
       "...                                                  ...    ...   \n",
       "18103  [None, 1, 1, 1, 1, 1, 2, 1/2, 1, 1, 1, 1/2, 1,...    NaN   \n",
       "18104  [None, 1, 1, 3, 1/3, 1, 1, 3, 1/3, 1, 1, 2, 1/...    NaN   \n",
       "18105  [None, 1, 1, 1, 1, 1/2, 1, 2, 1, 1, 1, 1, 1, 2...    NaN   \n",
       "18106  [None, 1/3, 3, 1/3, 3, 1/3, 3, 1/3, 3, 1/3, 3,...    NaN   \n",
       "18107  [None, 1, 1, 1, 2, 1/2, 1, 1, 1, 2, 1/2, 2, 1/...    NaN   \n",
       "\n",
       "      noncontentword wordend phoneme rhymes rhymescontentwords wordstress  \\\n",
       "0                NaN     NaN     NaN    NaN                NaN        NaN   \n",
       "1                NaN     NaN     NaN    NaN                NaN        NaN   \n",
       "2                NaN     NaN     NaN    NaN                NaN        NaN   \n",
       "3                NaN     NaN     NaN    NaN                NaN        NaN   \n",
       "4                NaN     NaN     NaN    NaN                NaN        NaN   \n",
       "...              ...     ...     ...    ...                ...        ...   \n",
       "18103            NaN     NaN     NaN    NaN                NaN        NaN   \n",
       "18104            NaN     NaN     NaN    NaN                NaN        NaN   \n",
       "18105            NaN     NaN     NaN    NaN                NaN        NaN   \n",
       "18106            NaN     NaN     NaN    NaN                NaN        NaN   \n",
       "18107            NaN     NaN     NaN    NaN                NaN        NaN   \n",
       "\n",
       "      melismastate  \n",
       "0              NaN  \n",
       "1              NaN  \n",
       "2              NaN  \n",
       "3              NaN  \n",
       "4              NaN  \n",
       "...            ...  \n",
       "18103          NaN  \n",
       "18104          NaN  \n",
       "18105          NaN  \n",
       "18106          NaN  \n",
       "18107          NaN  \n",
       "\n",
       "[18108 rows x 62 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_phrase = pd.DataFrame(phrase_data)\n",
    "df_phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "953fa1a9-d93d-42e7-8713-7f083f024b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'scaledegree', 'scaledegreespecifier', 'tonic', 'mode',\n",
       "       'metriccontour', 'imaweight', 'pitch40', 'midipitch', 'diatonicpitch',\n",
       "       'diatonicinterval', 'chromaticinterval', 'pitchproximity',\n",
       "       'pitchreversal', 'nextisrest', 'restduration_frac', 'duration',\n",
       "       'duration_frac', 'duration_fullname', 'onsettick', 'beatfraction',\n",
       "       'phrasepos', 'phrase_ix', 'phrase_end', 'songpos', 'beatinsong',\n",
       "       'beatinphrase', 'beatinphrase_end', 'IOI_frac', 'IOI', 'IOR',\n",
       "       'imacontour', 'pitch', 'contour3', 'contour5', 'beatstrength',\n",
       "       'beat_str', 'beat_fraction_str', 'beat', 'timesignature',\n",
       "       'gpr2a_Frankland', 'gpr2b_Frankland', 'gpr3a_Frankland',\n",
       "       'gpr3d_Frankland', 'gpr_Frankland_sum', 'lbdm_spitch', 'lbdm_sioi',\n",
       "       'lbdm_srest', 'lbdm_rpitch', 'lbdm_rioi', 'lbdm_rrest',\n",
       "       'lbdm_boundarystrength', 'durationcontour', 'IOR_frac', 'lyrics',\n",
       "       'noncontentword', 'wordend', 'phoneme', 'rhymes', 'rhymescontentwords',\n",
       "       'wordstress', 'melismastate'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_phrase.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21754b3",
   "metadata": {},
   "source": [
    "## Task 1: Choosing right attributes\n",
    "To make predictions for `phrase_end` (which indicates whether the tune is the ending of a song), first we need to determine which attributes affect the target attribute most. **Correlation analysis** is the best method for this purpose.  \n",
    "\n",
    "However, it requires only single numerical values. Since the values are stored in arrays for each song, we need to extract each individual tune and store them as a single record by applying the _explosion method_ to the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3be20937-77fd-481f-a77e-6cc6cc51ba70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scaledegree</th>\n",
       "      <th>scaledegreespecifier</th>\n",
       "      <th>tonic</th>\n",
       "      <th>mode</th>\n",
       "      <th>metriccontour</th>\n",
       "      <th>imaweight</th>\n",
       "      <th>pitch40</th>\n",
       "      <th>midipitch</th>\n",
       "      <th>diatonicpitch</th>\n",
       "      <th>diatonicinterval</th>\n",
       "      <th>...</th>\n",
       "      <th>IOR_frac</th>\n",
       "      <th>id</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>noncontentword</th>\n",
       "      <th>wordend</th>\n",
       "      <th>phoneme</th>\n",
       "      <th>rhymes</th>\n",
       "      <th>rhymescontentwords</th>\n",
       "      <th>wordstress</th>\n",
       "      <th>melismastate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>P</td>\n",
       "      <td>F</td>\n",
       "      <td>major</td>\n",
       "      <td>None</td>\n",
       "      <td>0.236646</td>\n",
       "      <td>163</td>\n",
       "      <td>72</td>\n",
       "      <td>32</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>NLB125815_01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>A</td>\n",
       "      <td>F</td>\n",
       "      <td>major</td>\n",
       "      <td>-</td>\n",
       "      <td>0.015528</td>\n",
       "      <td>164</td>\n",
       "      <td>73</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1/3</td>\n",
       "      <td>NLB125815_01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>M</td>\n",
       "      <td>F</td>\n",
       "      <td>major</td>\n",
       "      <td>+</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>169</td>\n",
       "      <td>74</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>NLB125815_01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>P</td>\n",
       "      <td>F</td>\n",
       "      <td>major</td>\n",
       "      <td>-</td>\n",
       "      <td>0.204348</td>\n",
       "      <td>163</td>\n",
       "      <td>72</td>\n",
       "      <td>32</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>NLB125815_01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>P</td>\n",
       "      <td>F</td>\n",
       "      <td>major</td>\n",
       "      <td>+</td>\n",
       "      <td>0.392547</td>\n",
       "      <td>157</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>NLB125815_01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  scaledegree scaledegreespecifier tonic   mode metriccontour imaweight  \\\n",
       "0           5                    P     F  major          None  0.236646   \n",
       "0           5                    A     F  major             -  0.015528   \n",
       "0           6                    M     F  major             +  0.913043   \n",
       "0           5                    P     F  major             -  0.204348   \n",
       "0           4                    P     F  major             +  0.392547   \n",
       "\n",
       "  pitch40 midipitch diatonicpitch diatonicinterval  ... IOR_frac  \\\n",
       "0     163        72            32             None  ...     None   \n",
       "0     164        73            32                0  ...      1/3   \n",
       "0     169        74            33                1  ...        4   \n",
       "0     163        72            32               -1  ...        1   \n",
       "0     157        70            31               -1  ...        1   \n",
       "\n",
       "             id lyrics noncontentword wordend phoneme rhymes  \\\n",
       "0  NLB125815_01    NaN            NaN     NaN     NaN    NaN   \n",
       "0  NLB125815_01    NaN            NaN     NaN     NaN    NaN   \n",
       "0  NLB125815_01    NaN            NaN     NaN     NaN    NaN   \n",
       "0  NLB125815_01    NaN            NaN     NaN     NaN    NaN   \n",
       "0  NLB125815_01    NaN            NaN     NaN     NaN    NaN   \n",
       "\n",
       "  rhymescontentwords wordstress melismastate  \n",
       "0                NaN        NaN          NaN  \n",
       "0                NaN        NaN          NaN  \n",
       "0                NaN        NaN          NaN  \n",
       "0                NaN        NaN          NaN  \n",
       "0                NaN        NaN          NaN  \n",
       "\n",
       "[5 rows x 62 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Select only the columns with sequence data and preserve other columns as metadata\n",
    "sequence_columns = [col for col in df_phrase.columns if isinstance(df_phrase[col].iloc[0], list)]\n",
    "non_sequence_columns = [col for col in df_phrase.columns if col not in sequence_columns]\n",
    "\n",
    "# Explode sequence columns\n",
    "df_exploded = df_phrase[sequence_columns].apply(pd.Series.explode)\n",
    "\n",
    "# Add back non-sequence metadata columns (e.g., 'id', 'phrase_end'), repeating their values\n",
    "for col in non_sequence_columns:\n",
    "    df_exploded[col] = df_phrase[col].repeat(df_phrase[sequence_columns[0]].str.len()).reset_index(drop=True)\n",
    "\n",
    "# Dataset after explosion\n",
    "df_exploded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57dea333",
   "metadata": {},
   "source": [
    "#### Now that every tune is stored as a single record, we can convert their values to numeric ones for the correlation analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eebb32a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/82/g6v1v3lj0pl0njbnhxvz04vm0000gn/T/ipykernel_22246/3015871042.py:7: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df_exploded[col] = pd.to_numeric(df_exploded[col], errors = \"ignore\")\n"
     ]
    }
   ],
   "source": [
    "# Converts phrase_end values to numeric ones (True -> 1, False -> 0)\n",
    "df_exploded[\"phrase_end\"] = df_exploded[\"phrase_end\"].astype(int)\n",
    "\n",
    "# Converts other columns to numeric ones (if possible)\n",
    "for col in df_exploded.columns:\n",
    "    if col != \"id\":\n",
    "        df_exploded[col] = pd.to_numeric(df_exploded[col], errors = \"ignore\")\n",
    "\n",
    "# Drops the 'id' column and chooses only the columns that were successfully converted to numeric\n",
    "df_numeric = df_exploded.drop(columns = [\"id\"]).select_dtypes(include = [\"number\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb843c3",
   "metadata": {},
   "source": [
    "#### `df_numeric` is the dataset that contains attributes whose values were successfully converted to numeric ones. Now we can perform the **correlation analysis.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "202c630e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phrase_end               1.000000\n",
      "lbdm_boundarystrength    0.491565\n",
      "phrasepos                0.481625\n",
      "lbdm_sioi                0.430348\n",
      "IOI                      0.399007\n",
      "duration                 0.397352\n",
      "IOR                      0.386167\n",
      "nextisrest               0.384382\n",
      "lbdm_srest               0.347842\n",
      "gpr2b_Frankland          0.291809\n",
      "gpr_Frankland_sum        0.255393\n",
      "lbdm_rrest               0.225675\n",
      "lbdm_spitch              0.223347\n",
      "lbdm_rioi                0.216156\n",
      "imaweight                0.186840\n",
      "beatstrength             0.170354\n",
      "gpr2a_Frankland          0.168731\n",
      "lbdm_rpitch              0.119988\n",
      "gpr3d_Frankland          0.118248\n",
      "songpos                  0.070903\n",
      "gpr3a_Frankland          0.057045\n",
      "phrase_ix                0.014938\n",
      "beat_str                -0.002449\n",
      "pitchreversal           -0.010129\n",
      "onsettick               -0.011849\n",
      "pitchproximity          -0.019382\n",
      "beat                    -0.063904\n",
      "diatonicinterval        -0.090256\n",
      "scaledegree             -0.090477\n",
      "chromaticinterval       -0.100981\n",
      "diatonicpitch           -0.107615\n",
      "pitch40                 -0.122948\n",
      "midipitch               -0.124859\n",
      "lyrics                        NaN\n",
      "noncontentword                NaN\n",
      "wordend                       NaN\n",
      "phoneme                       NaN\n",
      "rhymes                        NaN\n",
      "rhymescontentwords            NaN\n",
      "wordstress                    NaN\n",
      "melismastate                  NaN\n",
      "Name: phrase_end, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "correlation_matrix = df_numeric.corr()\n",
    "\n",
    "# Display correlations with \"phrase_end\"\n",
    "correlation_with_target = correlation_matrix[\"phrase_end\"].sort_values(ascending = False)\n",
    "print(correlation_with_target)\n",
    "\n",
    "# Drop the target column from the correlation data\n",
    "correlation_without_target = correlation_with_target.drop(\"phrase_end\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a39dfea-e568-4c4b-ba92-6a1ba2f2f566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Select the top 10 correlated features\n",
    "top_10_features = correlation_without_target.head(10)\n",
    "\n",
    "# Plot the top 10 features as a bar chart\n",
    "plt.figure(figsize=(10, 5))\n",
    "top_10_features.plot(kind=\"bar\")\n",
    "plt.title(\"Top 10 Correlated Features with 'phrase_end'\")\n",
    "plt.ylabel(\"Correlation Coefficient\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7c1280",
   "metadata": {},
   "source": [
    "##### From the bar chart, we can see the top 10 attributes that are correlated more with the target attribute than others. We will apply a threshold of *0.2* to choose only the best attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df3806d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features: ['lbdm_boundarystrength', 'phrasepos', 'lbdm_sioi', 'IOI', 'duration', 'IOR', 'nextisrest', 'lbdm_srest', 'gpr2b_Frankland', 'gpr_Frankland_sum', 'lbdm_rrest', 'lbdm_spitch', 'lbdm_rioi']\n"
     ]
    }
   ],
   "source": [
    "selected_features = correlation_with_target[correlation_with_target.abs() > 0.2].index.tolist()\n",
    "selected_features.remove('phrase_end') # Exclude the target variable\n",
    "print(\"Selected Features:\", selected_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bc094f",
   "metadata": {},
   "source": [
    "## Task 2: Training models\n",
    "\n",
    "We chose 4 models to predict our target variable: \n",
    "* Logistic Regression\n",
    "* Decision Tree\n",
    "* Random Forest\n",
    "* Neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce4e8ed",
   "metadata": {},
   "source": [
    "Before training the models on this dataset, we have to make sure that the dataset is fully prepared for training. Unfortunately, there is one problem: **NaN** values are scattered everywhere in the dataset. Some attributes have many, while others contain a small portion of it. We decided to implement different strategies to solve this problem:\n",
    "1. **Columns with more than 90% NaN values**: These attributes will not significantly affect the predictions since the majority of values are NaN. Therefore, we can confidently remove these columns.\n",
    "2. **Columns with a moderate number of NaN values**: We can use *imputation*, which fills NaN values with certain values obtained using a strategy such as *mean, median,* or *mod*. We chose to use *mean imputation*, meaning that for a single column, the average of its values will be computed, then all NaN values will be replaced by this value. This helps to keep the relationship between values.\n",
    "3. **Columns with relatively few NaN values**: Since these columns are critical for predictions, the best method is to *remove the records* where these columns have NaN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d7e7bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scaledegree                    0\n",
      "imaweight                      0\n",
      "pitch40                        0\n",
      "midipitch                      0\n",
      "diatonicpitch                  0\n",
      "diatonicinterval           18108\n",
      "chromaticinterval          18108\n",
      "pitchproximity             52596\n",
      "pitchreversal              56809\n",
      "nextisrest                 14470\n",
      "duration                       0\n",
      "onsettick                      0\n",
      "phrasepos                      0\n",
      "phrase_ix                      0\n",
      "phrase_end                     0\n",
      "songpos                        0\n",
      "IOI                        14470\n",
      "IOR                        32578\n",
      "beatstrength               43556\n",
      "beat_str                   43556\n",
      "beat                       43556\n",
      "gpr2a_Frankland          1271573\n",
      "gpr2b_Frankland          1111054\n",
      "gpr3a_Frankland          1065652\n",
      "gpr3d_Frankland           889668\n",
      "gpr_Frankland_sum              0\n",
      "lbdm_spitch                54324\n",
      "lbdm_sioi                  54324\n",
      "lbdm_srest                 54324\n",
      "lbdm_rpitch                36216\n",
      "lbdm_rioi                  36216\n",
      "lbdm_rrest                 36216\n",
      "lbdm_boundarystrength      54324\n",
      "lyrics                   1296028\n",
      "noncontentword           1296028\n",
      "wordend                  1296028\n",
      "phoneme                  1296028\n",
      "rhymes                   1296028\n",
      "rhymescontentwords       1296028\n",
      "wordstress               1296028\n",
      "melismastate             1296028\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_numeric.isna().sum()) # To determine the number of NaN values for each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f836ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# 1. Dropping columns with majority of values being NaN \n",
    "threshold = 0.9 * len(df_numeric)\n",
    "df_numeric = df_numeric.loc[:, df_numeric.isna().sum() < threshold]\n",
    "\n",
    "# 2. Removing rows where critical columns have NaN values\n",
    "critical_columns = [\"nextisrest\", \"diatonicinterval\", \"chromaticinterval\", \"IOI\"]\n",
    "df_numeric = df_numeric.dropna(subset = critical_columns)\n",
    "\n",
    "# 3. Mean imputation for columns with moderate number of NaN values\n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(strategy = \"mean\")\n",
    "df_numeric.iloc[:, :] = imputer.fit_transform(df_numeric)\n",
    "\n",
    "# Verifying that there are no remaining NaN values\n",
    "print(df_numeric.isna().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c4b64b",
   "metadata": {},
   "source": [
    "##### The data is ready. Now we can split the data into training and test sets, and train models for making predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aaa07849",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Splitting the dataset\n",
    "X = df_numeric.drop(columns = ['phrase_end']) # Features\n",
    "X = X[selected_features] # Choosing only important attributes\n",
    "y = df_numeric['phrase_end'] # Target\n",
    "\n",
    "# Split into training and test sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7732f507",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "95f2b039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.996221\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Initializing the Logistic Regression model\n",
    "# - max_iter: Maximum number of iterations for convergence (increased for stability)\n",
    "# - class_weight: Handles class imbalance by assigning weights inversely proportional to class frequencies\n",
    "# - random_state: Ensures reproducibility of results\n",
    "log_reg = LogisticRegression(max_iter=1000, class_weight=\"balanced\", random_state=42)\n",
    "\n",
    "# Fitting the Logistic Regression model to the training data\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions on the test set\n",
    "log_reg_pred = log_reg.predict(X_test)\n",
    "\n",
    "# Calculating the accuracy of the Logistic Regression model\n",
    "log_reg_acc = accuracy_score(y_test, log_reg_pred)\n",
    "\n",
    "print(f\"Logistic Regression Accuracy: {log_reg_acc:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9759b49d",
   "metadata": {},
   "source": [
    "The accuracy of the Logistic Regression is 1.00 (100%), which means that the model is likely *overfitting*. Even though we know that the correlation coefficients of the selected attributes are moderate to low, there could still be a high reliance on a single attribute to predict the target. To verify this, we can look at Logistic Regression coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "218a4c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phrasepos                96.625284\n",
      "gpr2b_Frankland          12.868939\n",
      "lbdm_srest                8.753301\n",
      "nextisrest                5.533051\n",
      "IOI                       4.288747\n",
      "lbdm_rrest                4.177195\n",
      "duration                  1.741313\n",
      "lbdm_boundarystrength     1.531766\n",
      "lbdm_spitch               1.320539\n",
      "gpr_Frankland_sum         1.081885\n",
      "lbdm_sioi                 0.652848\n",
      "IOR                       0.501464\n",
      "lbdm_rioi                 0.272318\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "importance = np.abs(log_reg.coef_[0]) # Taking absolute values to make the comparison easier\n",
    "feature_importance = pd.Series(importance, index = X_train.columns).sort_values(ascending = False)\n",
    "print(feature_importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8de65b",
   "metadata": {},
   "source": [
    "We can see that `phrasepos` attribute has very high coefficient magnitude compared to others. This means that the model heavily relies on it to make predictions, not accounting for the input from other features. So, the model is not generalizing, but rather making predictions based on the `phrasepos` attribute. So, we will remove it from the dataset and train the model again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "10e0796d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset without 'phrasepos' column\n",
    "X_train_reduced = X_train.drop(columns = [\"phrasepos\"])\n",
    "X_test_reduced = X_test.drop(columns = [\"phrasepos\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c8b41a7c-1da2-4641-b09b-f39c0f914f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.839851\n"
     ]
    }
   ],
   "source": [
    "# Training the Logistic Regression Model again with new reduced data\n",
    "log_reg.fit(X_train_reduced, y_train)\n",
    "\n",
    "# Making predictions again\n",
    "log_reg_pred = log_reg.predict(X_test_reduced)\n",
    "\n",
    "# Calculating new accuracy score\n",
    "log_reg_acc = accuracy_score(y_test, log_reg_pred)\n",
    "\n",
    "print(f\"Logistic Regression Accuracy: {log_reg_acc:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df90b31",
   "metadata": {},
   "source": [
    "##### Accuracy of the model dropped. This shows that there is no overfitting and the model is doing a great job in generalization. Let's make sure that feature importance coefficients are evenly distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fa170517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nextisrest               5.419989\n",
      "lbdm_rrest               2.789008\n",
      "gpr2b_Frankland          2.154717\n",
      "lbdm_spitch              1.485973\n",
      "lbdm_sioi                1.238513\n",
      "lbdm_boundarystrength    1.028863\n",
      "duration                 1.021846\n",
      "gpr_Frankland_sum        0.704102\n",
      "lbdm_rioi                0.199816\n",
      "lbdm_srest               0.152452\n",
      "IOR                      0.140650\n",
      "IOI                      0.112607\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "importance = np.abs(log_reg.coef_[0]) # Taking absolute values to make the comparison easier\n",
    "feature_importance = pd.Series(importance, index = X_train_reduced.columns).sort_values(ascending = False)\n",
    "print(feature_importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d224702e",
   "metadata": {},
   "source": [
    "##### This table confirms that the importance is evenly distributed on the features. So, it is a great result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd9554c",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b3a34bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 0.940603\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.tree import DecisionTreeClassifier, export_text, plot_tree\n",
    "\n",
    "# Initialize the Decision Tree model\n",
    "decision_tree = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Train the Decision Tree model on the reduced training dataset\n",
    "decision_tree.fit(X_train_reduced, y_train)\n",
    "\n",
    "# Make predictions on the reduced test dataset\n",
    "decision_tree_pred = decision_tree.predict(X_test_reduced)\n",
    "\n",
    "# Calculate the accuracy of the Decision Tree model\n",
    "decision_tree_acc = accuracy_score(y_test, decision_tree_pred)\n",
    "\n",
    "print(f\"Decision Tree Accuracy: {decision_tree_acc:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e3dc5a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commented out as the output is way too long.\n",
    "\n",
    "# # Visualize the decision tree in a text-based format\n",
    "# tree_rules = export_text(decision_tree, feature_names=X_train_reduced.columns.tolist())\n",
    "# print(tree_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98bd218-688d-40ad-93ee-a590641d3a38",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Image size of 90000x60000 pixels is too large. It must be less than 2^16 in each direction.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m plot_tree(decision_tree, feature_names\u001b[38;5;241m=\u001b[39mX_train_reduced\u001b[38;5;241m.\u001b[39mcolumns, class_names\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, filled\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Save the figure to a file\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m plt\u001b[38;5;241m.\u001b[39msavefig(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecision_tree_plot.png\u001b[39m\u001b[38;5;124m\"\u001b[39m, dpi\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m300\u001b[39m, bbox_inches\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtight\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/matplotlib/pyplot.py:1228\u001b[0m, in \u001b[0;36msavefig\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1225\u001b[0m fig \u001b[38;5;241m=\u001b[39m gcf()\n\u001b[1;32m   1226\u001b[0m \u001b[38;5;66;03m# savefig default implementation has no return, so mypy is unhappy\u001b[39;00m\n\u001b[1;32m   1227\u001b[0m \u001b[38;5;66;03m# presumably this is here because subclasses can return?\u001b[39;00m\n\u001b[0;32m-> 1228\u001b[0m res \u001b[38;5;241m=\u001b[39m fig\u001b[38;5;241m.\u001b[39msavefig(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[func-returns-value]\u001b[39;00m\n\u001b[1;32m   1229\u001b[0m fig\u001b[38;5;241m.\u001b[39mcanvas\u001b[38;5;241m.\u001b[39mdraw_idle()  \u001b[38;5;66;03m# Need this if 'transparent=True', to reset colors.\u001b[39;00m\n\u001b[1;32m   1230\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/matplotlib/figure.py:3395\u001b[0m, in \u001b[0;36mFigure.savefig\u001b[0;34m(self, fname, transparent, **kwargs)\u001b[0m\n\u001b[1;32m   3393\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ax \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes:\n\u001b[1;32m   3394\u001b[0m         _recursively_make_axes_transparent(stack, ax)\n\u001b[0;32m-> 3395\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcanvas\u001b[38;5;241m.\u001b[39mprint_figure(fname, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/matplotlib/backend_bases.py:2167\u001b[0m, in \u001b[0;36mFigureCanvasBase.print_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[1;32m   2162\u001b[0m layout_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure\u001b[38;5;241m.\u001b[39mget_layout_engine()\n\u001b[1;32m   2163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m layout_engine \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m bbox_inches \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtight\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   2164\u001b[0m     \u001b[38;5;66;03m# we need to trigger a draw before printing to make sure\u001b[39;00m\n\u001b[1;32m   2165\u001b[0m     \u001b[38;5;66;03m# CL works.  \"tight\" also needs a draw to get the right\u001b[39;00m\n\u001b[1;32m   2166\u001b[0m     \u001b[38;5;66;03m# locations:\u001b[39;00m\n\u001b[0;32m-> 2167\u001b[0m     renderer \u001b[38;5;241m=\u001b[39m _get_renderer(\n\u001b[1;32m   2168\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure,\n\u001b[1;32m   2169\u001b[0m         functools\u001b[38;5;241m.\u001b[39mpartial(\n\u001b[1;32m   2170\u001b[0m             print_method, orientation\u001b[38;5;241m=\u001b[39morientation)\n\u001b[1;32m   2171\u001b[0m     )\n\u001b[1;32m   2172\u001b[0m     \u001b[38;5;66;03m# we do this instead of `self.figure.draw_without_rendering`\u001b[39;00m\n\u001b[1;32m   2173\u001b[0m     \u001b[38;5;66;03m# so that we can inject the orientation\u001b[39;00m\n\u001b[1;32m   2174\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(renderer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_draw_disabled\u001b[39m\u001b[38;5;124m\"\u001b[39m, nullcontext)():\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/matplotlib/backend_bases.py:1588\u001b[0m, in \u001b[0;36m_get_renderer\u001b[0;34m(figure, print_method)\u001b[0m\n\u001b[1;32m   1585\u001b[0m     print_method \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\n\u001b[1;32m   1586\u001b[0m         figure\u001b[38;5;241m.\u001b[39mcanvas\u001b[38;5;241m.\u001b[39m_switch_canvas_and_return_print_method(fmt))\n\u001b[1;32m   1587\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1588\u001b[0m     print_method(io\u001b[38;5;241m.\u001b[39mBytesIO())\n\u001b[1;32m   1589\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m Done \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m   1590\u001b[0m     renderer, \u001b[38;5;241m=\u001b[39m exc\u001b[38;5;241m.\u001b[39margs\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/matplotlib/backend_bases.py:2054\u001b[0m, in \u001b[0;36mFigureCanvasBase._switch_canvas_and_return_print_method.<locals>.<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   2050\u001b[0m     optional_kws \u001b[38;5;241m=\u001b[39m {  \u001b[38;5;66;03m# Passed by print_figure for other renderers.\u001b[39;00m\n\u001b[1;32m   2051\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdpi\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfacecolor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124medgecolor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morientation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2052\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbbox_inches_restore\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m   2053\u001b[0m     skip \u001b[38;5;241m=\u001b[39m optional_kws \u001b[38;5;241m-\u001b[39m {\u001b[38;5;241m*\u001b[39minspect\u001b[38;5;241m.\u001b[39msignature(meth)\u001b[38;5;241m.\u001b[39mparameters}\n\u001b[0;32m-> 2054\u001b[0m     print_method \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mwraps(meth)(\u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: meth(\n\u001b[1;32m   2055\u001b[0m         \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m skip}))\n\u001b[1;32m   2056\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# Let third-parties do as they see fit.\u001b[39;00m\n\u001b[1;32m   2057\u001b[0m     print_method \u001b[38;5;241m=\u001b[39m meth\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/matplotlib/backends/backend_agg.py:496\u001b[0m, in \u001b[0;36mFigureCanvasAgg.print_png\u001b[0;34m(self, filename_or_obj, metadata, pil_kwargs)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprint_png\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename_or_obj, \u001b[38;5;241m*\u001b[39m, metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, pil_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    450\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;124;03m    Write the figure to a PNG file.\u001b[39;00m\n\u001b[1;32m    452\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;124;03m        *metadata*, including the default 'Software' key.\u001b[39;00m\n\u001b[1;32m    495\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 496\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_print_pil(filename_or_obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpng\u001b[39m\u001b[38;5;124m\"\u001b[39m, pil_kwargs, metadata)\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/matplotlib/backends/backend_agg.py:444\u001b[0m, in \u001b[0;36mFigureCanvasAgg._print_pil\u001b[0;34m(self, filename_or_obj, fmt, pil_kwargs, metadata)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_print_pil\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename_or_obj, fmt, pil_kwargs, metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    440\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;124;03m    Draw the canvas, then save it using `.image.imsave` (to which\u001b[39;00m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;124;03m    *pil_kwargs* and *metadata* are forwarded).\u001b[39;00m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 444\u001b[0m     FigureCanvasAgg\u001b[38;5;241m.\u001b[39mdraw(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    445\u001b[0m     mpl\u001b[38;5;241m.\u001b[39mimage\u001b[38;5;241m.\u001b[39mimsave(\n\u001b[1;32m    446\u001b[0m         filename_or_obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuffer_rgba(), \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39mfmt, origin\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mupper\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    447\u001b[0m         dpi\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure\u001b[38;5;241m.\u001b[39mdpi, metadata\u001b[38;5;241m=\u001b[39mmetadata, pil_kwargs\u001b[38;5;241m=\u001b[39mpil_kwargs)\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/matplotlib/backends/backend_agg.py:382\u001b[0m, in \u001b[0;36mFigureCanvasAgg.draw\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdraw\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    381\u001b[0m     \u001b[38;5;66;03m# docstring inherited\u001b[39;00m\n\u001b[0;32m--> 382\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrenderer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_renderer()\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrenderer\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;66;03m# Acquire a lock on the shared font cache.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/matplotlib/backends/backend_agg.py:397\u001b[0m, in \u001b[0;36mFigureCanvasAgg.get_renderer\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    395\u001b[0m reuse_renderer \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lastKey \u001b[38;5;241m==\u001b[39m key)\n\u001b[1;32m    396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m reuse_renderer:\n\u001b[0;32m--> 397\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrenderer \u001b[38;5;241m=\u001b[39m RendererAgg(w, h, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure\u001b[38;5;241m.\u001b[39mdpi)\n\u001b[1;32m    398\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lastKey \u001b[38;5;241m=\u001b[39m key\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrenderer\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/matplotlib/backends/backend_agg.py:70\u001b[0m, in \u001b[0;36mRendererAgg.__init__\u001b[0;34m(self, width, height, dpi)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwidth \u001b[38;5;241m=\u001b[39m width\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheight \u001b[38;5;241m=\u001b[39m height\n\u001b[0;32m---> 70\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_renderer \u001b[38;5;241m=\u001b[39m _RendererAgg(\u001b[38;5;28mint\u001b[39m(width), \u001b[38;5;28mint\u001b[39m(height), dpi)\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_filter_renderers \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_methods()\n",
      "\u001b[0;31mValueError\u001b[0m: Image size of 90000x60000 pixels is too large. It must be less than 2^16 in each direction."
     ]
    }
   ],
   "source": [
    "# Takes too much time to compute, not necessary\n",
    "\n",
    "# # Visualize the decision tree as a graphical plot\n",
    "# plt.figure(figsize=(120, 80))\n",
    "# plot_tree(decision_tree, feature_names=X_train_reduced.columns, class_names=True, filled=True)\n",
    "\n",
    "# # Save the figure to a file\n",
    "# plt.savefig(\"decision_tree_plot.png\", dpi=300, bbox_inches='tight')  # Save with high resolution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c0d945",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfaf6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "# - random_state: Ensures reproducibility of results\n",
    "random_forest = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Train the Random Forest model on the reduced training dataset\n",
    "random_forest.fit(X_train_reduced, y_train)\n",
    "\n",
    "# Make predictions on the reduced test dataset\n",
    "random_forest_pred = random_forest.predict(X_test_reduced)\n",
    "\n",
    "# Calculate the accuracy of the Random Forest model\n",
    "random_forest_acc = accuracy_score(y_test, random_forest_pred)\n",
    "\n",
    "print(f\"Random Forest Accuracy: {random_forest_acc:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d97801",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d95197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Initialize the Neural Network model\n",
    "# - hidden_layer_sizes: Defines the structure of the hidden layers. Here, a single hidden layer with 100 neurons.\n",
    "# - max_iter: Maximum number of iterations for optimization (training) to converge.\n",
    "# - random_state: Ensures reproducibility of the results.\n",
    "neural_net = MLPClassifier(hidden_layer_sizes=(100,), max_iter=1000, random_state=42)\n",
    "\n",
    "# Train the Neural Network model on the reduced training dataset\n",
    "neural_net.fit(X_train_reduced, y_train)\n",
    "\n",
    "# Make predictions on the reduced test dataset\n",
    "neural_net_pred = neural_net.predict(X_test_reduced)\n",
    "\n",
    "# Calculate the accuracy of the Neural Network model\n",
    "neural_net_acc = accuracy_score(y_test, neural_net_pred)\n",
    "\n",
    "print(f\"Neural Network Accuracy: {neural_net_acc:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e037909",
   "metadata": {},
   "source": [
    "### Accuracy scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbbc3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy Scores\\n\")\n",
    "print(f\"Logistic Regression: {log_reg_acc:.6f}\")\n",
    "print(f\"Decision Tree: {decision_tree_acc:.6f}\")\n",
    "print(f\"Random Forest: {random_forest_acc:.6f}\")\n",
    "print(f\"Neural Network: {neural_net_acc:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1a0fe7",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "To conclude, we can say that **Yigit** is from **Türkiye**, and **Shamkhal** is from **Azerbaijan**. This makes them **_kardeşler_** by blood.  \n",
    "(Of course we will modify this later mate ahah)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
