{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6baa9f52",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "\n",
    "# <span style=\"color: red;\">Science des Données (SD)</span>\n",
    "## <span style=\"color: black;\">2024 - 2025 Project</span>\n",
    "\n",
    "## <span></span>\n",
    "## <span style=\"color: black;\">Shamkhal GULIYEV</span>, <span style=\"color: black;\">Yigit YUMUS</span>\n",
    "### <span></span>\n",
    "### <span></span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f03237-a27b-4415-aa07-b7b7b2420ec3",
   "metadata": {},
   "source": [
    "### Useful Resource:\n",
    "- **Package**: [MTCFeatures](https://pvankranenburg.github.io/MTCFeatures/)  \n",
    "  A detailed overview of the MTCFeatures package is available at the above link."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f65e35c-053f-425c-9038-caef6e8f4f58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1dbf05c-c3e4-4983-ae0f-3cb6d6fc6b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary packages (uncomment if not already installed)\n",
    "# !{sys.executable} -m pip install mtcfeatures pandas numpy matplotlib scikit-learn\n",
    "\n",
    "from MTCFeatures import MTCFeatureLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40ed33d1-4a7c-458b-a7d1-10899c319737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Run once\n",
    "\n",
    "# import MTCFeatures\n",
    "# MTCFeatures.downloadData(dest='user')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b02d5b77-9385-49d5-9f22-b3237ebebde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MTC feature dataset using the MTCFeatureLoader\n",
    "fl = MTCFeatureLoader('MTC-FS-INST-2.0')\n",
    "\n",
    "# Retrieve all sequences from the loaded dataset\n",
    "# It contains musical or feature-related sequences for analysis\n",
    "seqs = fl.sequences()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b3c545e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "generator"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f2165f2-1e2a-4748-b2ce-aae1f66e6c37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'NLB125814_01',\n",
       " 'tunefamily': '11965_0',\n",
       " 'year': 1884,\n",
       " 'tunefamily_full': 'Ach wie ist es möglich denn',\n",
       " 'type': 'instrumental',\n",
       " 'freemeter': False,\n",
       " 'features': {'scaledegree': [3,\n",
       "   1,\n",
       "   6,\n",
       "   5,\n",
       "   1,\n",
       "   1,\n",
       "   2,\n",
       "   1,\n",
       "   2,\n",
       "   3,\n",
       "   6,\n",
       "   5,\n",
       "   5,\n",
       "   4,\n",
       "   5,\n",
       "   6,\n",
       "   4,\n",
       "   3,\n",
       "   2,\n",
       "   3,\n",
       "   2,\n",
       "   5,\n",
       "   2,\n",
       "   3,\n",
       "   2,\n",
       "   1,\n",
       "   6,\n",
       "   5,\n",
       "   3,\n",
       "   4,\n",
       "   3,\n",
       "   6,\n",
       "   3,\n",
       "   2,\n",
       "   5,\n",
       "   6,\n",
       "   5,\n",
       "   5,\n",
       "   4,\n",
       "   3,\n",
       "   2,\n",
       "   6,\n",
       "   7,\n",
       "   1],\n",
       "  'scaledegreespecifier': ['M',\n",
       "   'P',\n",
       "   'M',\n",
       "   'P',\n",
       "   'P',\n",
       "   'P',\n",
       "   'M',\n",
       "   'P',\n",
       "   'M',\n",
       "   'M',\n",
       "   'M',\n",
       "   'P',\n",
       "   'P',\n",
       "   'A',\n",
       "   'P',\n",
       "   'M',\n",
       "   'P',\n",
       "   'M',\n",
       "   'M',\n",
       "   'M',\n",
       "   'M',\n",
       "   'P',\n",
       "   'M',\n",
       "   'M',\n",
       "   'M',\n",
       "   'P',\n",
       "   'M',\n",
       "   'P',\n",
       "   'M',\n",
       "   'P',\n",
       "   'M',\n",
       "   'M',\n",
       "   'M',\n",
       "   'M',\n",
       "   'P',\n",
       "   'M',\n",
       "   'P',\n",
       "   'P',\n",
       "   'P',\n",
       "   'M',\n",
       "   'M',\n",
       "   'M',\n",
       "   'M',\n",
       "   'P'],\n",
       "  'tonic': ['C',\n",
       "   'C',\n",
       "   'C',\n",
       "   'C',\n",
       "   'C',\n",
       "   'C',\n",
       "   'C',\n",
       "   'C',\n",
       "   'C',\n",
       "   'C',\n",
       "   'C',\n",
       "   'C',\n",
       "   'C',\n",
       "   'C',\n",
       "   'C',\n",
       "   'C',\n",
       "   'C',\n",
       "   'C',\n",
       "   'C',\n",
       "   'C',\n",
       "   'C',\n",
       "   'C',\n",
       "   'C',\n",
       "   'C',\n",
       "   'C',\n",
       "   'C',\n",
       "   'C',\n",
       "   'C',\n",
       "   'C',\n",
       "   'C',\n",
       "   'C',\n",
       "   'C',\n",
       "   'C',\n",
       "   'C',\n",
       "   'C',\n",
       "   'C',\n",
       "   'C',\n",
       "   'C',\n",
       "   'C',\n",
       "   'C',\n",
       "   'C',\n",
       "   'C',\n",
       "   'C',\n",
       "   'C'],\n",
       "  'mode': ['major',\n",
       "   'major',\n",
       "   'major',\n",
       "   'major',\n",
       "   'major',\n",
       "   'major',\n",
       "   'major',\n",
       "   'major',\n",
       "   'major',\n",
       "   'major',\n",
       "   'major',\n",
       "   'major',\n",
       "   'major',\n",
       "   'major',\n",
       "   'major',\n",
       "   'major',\n",
       "   'major',\n",
       "   'major',\n",
       "   'major',\n",
       "   'major',\n",
       "   'major',\n",
       "   'major',\n",
       "   'major',\n",
       "   'major',\n",
       "   'major',\n",
       "   'major',\n",
       "   'major',\n",
       "   'major',\n",
       "   'major',\n",
       "   'major',\n",
       "   'major',\n",
       "   'major',\n",
       "   'major',\n",
       "   'major',\n",
       "   'major',\n",
       "   'major',\n",
       "   'major',\n",
       "   'major',\n",
       "   'major',\n",
       "   'major',\n",
       "   'major',\n",
       "   'major',\n",
       "   'major',\n",
       "   'major'],\n",
       "  'metriccontour': [None,\n",
       "   '-',\n",
       "   '-',\n",
       "   '+',\n",
       "   '-',\n",
       "   '+',\n",
       "   '+',\n",
       "   '-',\n",
       "   '-',\n",
       "   '+',\n",
       "   '-',\n",
       "   '+',\n",
       "   '+',\n",
       "   '-',\n",
       "   '-',\n",
       "   '+',\n",
       "   '-',\n",
       "   '+',\n",
       "   '+',\n",
       "   '-',\n",
       "   '-',\n",
       "   '+',\n",
       "   '=',\n",
       "   '-',\n",
       "   '-',\n",
       "   '+',\n",
       "   '-',\n",
       "   '+',\n",
       "   '+',\n",
       "   '-',\n",
       "   '-',\n",
       "   '+',\n",
       "   '-',\n",
       "   '+',\n",
       "   '+',\n",
       "   '-',\n",
       "   '-',\n",
       "   '+',\n",
       "   '-',\n",
       "   '+',\n",
       "   '+',\n",
       "   '-',\n",
       "   '-',\n",
       "   '+'],\n",
       "  'imaweight': [0.798013,\n",
       "   0.663907,\n",
       "   0.150662,\n",
       "   0.945364,\n",
       "   0.013245,\n",
       "   0.524834,\n",
       "   0.93543,\n",
       "   0.673841,\n",
       "   0.195364,\n",
       "   0.812914,\n",
       "   0.162252,\n",
       "   0.627483,\n",
       "   0.951987,\n",
       "   0.59106,\n",
       "   0.228477,\n",
       "   0.927152,\n",
       "   0.183775,\n",
       "   0.642384,\n",
       "   0.837748,\n",
       "   0.692053,\n",
       "   0.25,\n",
       "   1.0,\n",
       "   0.998344,\n",
       "   0.715232,\n",
       "   0.243377,\n",
       "   0.870861,\n",
       "   0.205298,\n",
       "   0.630795,\n",
       "   0.917219,\n",
       "   0.614238,\n",
       "   0.221854,\n",
       "   0.942053,\n",
       "   0.162252,\n",
       "   0.652318,\n",
       "   0.84106,\n",
       "   0.652318,\n",
       "   0.183775,\n",
       "   0.961921,\n",
       "   0.145695,\n",
       "   0.551325,\n",
       "   0.94702,\n",
       "   0.690397,\n",
       "   0.153974,\n",
       "   0.791391],\n",
       "  'pitch40': [135,\n",
       "   123,\n",
       "   112,\n",
       "   106,\n",
       "   123,\n",
       "   123,\n",
       "   129,\n",
       "   123,\n",
       "   129,\n",
       "   135,\n",
       "   112,\n",
       "   106,\n",
       "   106,\n",
       "   101,\n",
       "   106,\n",
       "   112,\n",
       "   140,\n",
       "   135,\n",
       "   129,\n",
       "   135,\n",
       "   129,\n",
       "   106,\n",
       "   129,\n",
       "   135,\n",
       "   129,\n",
       "   123,\n",
       "   112,\n",
       "   106,\n",
       "   135,\n",
       "   140,\n",
       "   135,\n",
       "   112,\n",
       "   135,\n",
       "   129,\n",
       "   106,\n",
       "   112,\n",
       "   106,\n",
       "   106,\n",
       "   140,\n",
       "   135,\n",
       "   129,\n",
       "   112,\n",
       "   118,\n",
       "   123],\n",
       "  'midipitch': [64,\n",
       "   60,\n",
       "   57,\n",
       "   55,\n",
       "   60,\n",
       "   60,\n",
       "   62,\n",
       "   60,\n",
       "   62,\n",
       "   64,\n",
       "   57,\n",
       "   55,\n",
       "   55,\n",
       "   54,\n",
       "   55,\n",
       "   57,\n",
       "   65,\n",
       "   64,\n",
       "   62,\n",
       "   64,\n",
       "   62,\n",
       "   55,\n",
       "   62,\n",
       "   64,\n",
       "   62,\n",
       "   60,\n",
       "   57,\n",
       "   55,\n",
       "   64,\n",
       "   65,\n",
       "   64,\n",
       "   57,\n",
       "   64,\n",
       "   62,\n",
       "   55,\n",
       "   57,\n",
       "   55,\n",
       "   55,\n",
       "   65,\n",
       "   64,\n",
       "   62,\n",
       "   57,\n",
       "   59,\n",
       "   60],\n",
       "  'diatonicpitch': [30,\n",
       "   28,\n",
       "   26,\n",
       "   25,\n",
       "   28,\n",
       "   28,\n",
       "   29,\n",
       "   28,\n",
       "   29,\n",
       "   30,\n",
       "   26,\n",
       "   25,\n",
       "   25,\n",
       "   24,\n",
       "   25,\n",
       "   26,\n",
       "   31,\n",
       "   30,\n",
       "   29,\n",
       "   30,\n",
       "   29,\n",
       "   25,\n",
       "   29,\n",
       "   30,\n",
       "   29,\n",
       "   28,\n",
       "   26,\n",
       "   25,\n",
       "   30,\n",
       "   31,\n",
       "   30,\n",
       "   26,\n",
       "   30,\n",
       "   29,\n",
       "   25,\n",
       "   26,\n",
       "   25,\n",
       "   25,\n",
       "   31,\n",
       "   30,\n",
       "   29,\n",
       "   26,\n",
       "   27,\n",
       "   28],\n",
       "  'diatonicinterval': [None,\n",
       "   -2,\n",
       "   -2,\n",
       "   -1,\n",
       "   3,\n",
       "   0,\n",
       "   1,\n",
       "   -1,\n",
       "   1,\n",
       "   1,\n",
       "   -4,\n",
       "   -1,\n",
       "   0,\n",
       "   -1,\n",
       "   1,\n",
       "   1,\n",
       "   5,\n",
       "   -1,\n",
       "   -1,\n",
       "   1,\n",
       "   -1,\n",
       "   -4,\n",
       "   4,\n",
       "   1,\n",
       "   -1,\n",
       "   -1,\n",
       "   -2,\n",
       "   -1,\n",
       "   5,\n",
       "   1,\n",
       "   -1,\n",
       "   -4,\n",
       "   4,\n",
       "   -1,\n",
       "   -4,\n",
       "   1,\n",
       "   -1,\n",
       "   0,\n",
       "   6,\n",
       "   -1,\n",
       "   -1,\n",
       "   -3,\n",
       "   1,\n",
       "   1],\n",
       "  'chromaticinterval': [None,\n",
       "   -4,\n",
       "   -3,\n",
       "   -2,\n",
       "   5,\n",
       "   0,\n",
       "   2,\n",
       "   -2,\n",
       "   2,\n",
       "   2,\n",
       "   -7,\n",
       "   -2,\n",
       "   0,\n",
       "   -1,\n",
       "   1,\n",
       "   2,\n",
       "   8,\n",
       "   -1,\n",
       "   -2,\n",
       "   2,\n",
       "   -2,\n",
       "   -7,\n",
       "   7,\n",
       "   2,\n",
       "   -2,\n",
       "   -2,\n",
       "   -3,\n",
       "   -2,\n",
       "   9,\n",
       "   1,\n",
       "   -1,\n",
       "   -7,\n",
       "   7,\n",
       "   -2,\n",
       "   -7,\n",
       "   2,\n",
       "   -2,\n",
       "   0,\n",
       "   10,\n",
       "   -1,\n",
       "   -2,\n",
       "   -5,\n",
       "   2,\n",
       "   1],\n",
       "  'pitchproximity': [None,\n",
       "   None,\n",
       "   3,\n",
       "   2,\n",
       "   5,\n",
       "   0,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   7,\n",
       "   2,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   2,\n",
       "   8,\n",
       "   1,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   7,\n",
       "   7,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   3,\n",
       "   2,\n",
       "   9,\n",
       "   1,\n",
       "   1,\n",
       "   7,\n",
       "   7,\n",
       "   2,\n",
       "   7,\n",
       "   2,\n",
       "   2,\n",
       "   0,\n",
       "   10,\n",
       "   1,\n",
       "   2,\n",
       "   5,\n",
       "   2,\n",
       "   1],\n",
       "  'pitchreversal': [None,\n",
       "   None,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1.5,\n",
       "   1.5,\n",
       "   0,\n",
       "   0,\n",
       "   -1,\n",
       "   0,\n",
       "   0,\n",
       "   1.5,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1.5,\n",
       "   1.5,\n",
       "   0,\n",
       "   2.5,\n",
       "   -1,\n",
       "   1.5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   -1,\n",
       "   1.5,\n",
       "   0,\n",
       "   2.5,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1.5,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'nextisrest': [False,\n",
       "   False,\n",
       "   False,\n",
       "   False,\n",
       "   False,\n",
       "   False,\n",
       "   False,\n",
       "   False,\n",
       "   False,\n",
       "   False,\n",
       "   False,\n",
       "   False,\n",
       "   False,\n",
       "   False,\n",
       "   False,\n",
       "   False,\n",
       "   False,\n",
       "   False,\n",
       "   False,\n",
       "   False,\n",
       "   False,\n",
       "   True,\n",
       "   False,\n",
       "   False,\n",
       "   False,\n",
       "   False,\n",
       "   False,\n",
       "   False,\n",
       "   False,\n",
       "   False,\n",
       "   False,\n",
       "   False,\n",
       "   False,\n",
       "   False,\n",
       "   False,\n",
       "   False,\n",
       "   False,\n",
       "   False,\n",
       "   False,\n",
       "   False,\n",
       "   False,\n",
       "   False,\n",
       "   False,\n",
       "   True],\n",
       "  'restduration_frac': [None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   '1',\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   '1/2'],\n",
       "  'duration': [1.0,\n",
       "   0.5,\n",
       "   0.5,\n",
       "   0.75,\n",
       "   0.25,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.5,\n",
       "   0.5,\n",
       "   0.5,\n",
       "   0.5,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.5,\n",
       "   0.5,\n",
       "   0.5,\n",
       "   0.5,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.5,\n",
       "   0.5,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.5,\n",
       "   0.5,\n",
       "   0.5,\n",
       "   0.5,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.5,\n",
       "   0.5,\n",
       "   0.5,\n",
       "   0.5,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.5,\n",
       "   0.5,\n",
       "   0.5,\n",
       "   0.5,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.5,\n",
       "   0.5,\n",
       "   1.5],\n",
       "  'duration_frac': ['1',\n",
       "   '1/2',\n",
       "   '1/2',\n",
       "   '3/4',\n",
       "   '1/4',\n",
       "   '1',\n",
       "   '1',\n",
       "   '1/2',\n",
       "   '1/2',\n",
       "   '1/2',\n",
       "   '1/2',\n",
       "   '1',\n",
       "   '1',\n",
       "   '1/2',\n",
       "   '1/2',\n",
       "   '1/2',\n",
       "   '1/2',\n",
       "   '1',\n",
       "   '1',\n",
       "   '1/2',\n",
       "   '1/2',\n",
       "   '1',\n",
       "   '1',\n",
       "   '1/2',\n",
       "   '1/2',\n",
       "   '1/2',\n",
       "   '1/2',\n",
       "   '1',\n",
       "   '1',\n",
       "   '1/2',\n",
       "   '1/2',\n",
       "   '1/2',\n",
       "   '1/2',\n",
       "   '1',\n",
       "   '1',\n",
       "   '1/2',\n",
       "   '1/2',\n",
       "   '1/2',\n",
       "   '1/2',\n",
       "   '1',\n",
       "   '1',\n",
       "   '1/2',\n",
       "   '1/2',\n",
       "   '3/2'],\n",
       "  'duration_fullname': ['Quarter',\n",
       "   'Eighth',\n",
       "   'Eighth',\n",
       "   'Dotted Eighth',\n",
       "   '16th',\n",
       "   'Quarter',\n",
       "   'Quarter',\n",
       "   'Eighth',\n",
       "   'Eighth',\n",
       "   'Eighth',\n",
       "   'Eighth',\n",
       "   'Quarter',\n",
       "   'Quarter',\n",
       "   'Eighth',\n",
       "   'Eighth',\n",
       "   'Eighth',\n",
       "   'Eighth',\n",
       "   'Quarter',\n",
       "   'Quarter',\n",
       "   'Eighth',\n",
       "   'Eighth',\n",
       "   'Quarter',\n",
       "   'Quarter',\n",
       "   'Eighth',\n",
       "   'Eighth',\n",
       "   'Eighth',\n",
       "   'Eighth',\n",
       "   'Quarter',\n",
       "   'Quarter',\n",
       "   'Eighth',\n",
       "   'Eighth',\n",
       "   'Eighth',\n",
       "   'Eighth',\n",
       "   'Quarter',\n",
       "   'Quarter',\n",
       "   'Eighth',\n",
       "   'Eighth',\n",
       "   'Eighth',\n",
       "   'Eighth',\n",
       "   'Quarter',\n",
       "   'Quarter',\n",
       "   'Eighth',\n",
       "   'Eighth',\n",
       "   'Dotted Quarter'],\n",
       "  'onsettick': [0,\n",
       "   4,\n",
       "   6,\n",
       "   8,\n",
       "   11,\n",
       "   12,\n",
       "   16,\n",
       "   20,\n",
       "   22,\n",
       "   24,\n",
       "   26,\n",
       "   28,\n",
       "   32,\n",
       "   36,\n",
       "   38,\n",
       "   40,\n",
       "   42,\n",
       "   44,\n",
       "   48,\n",
       "   52,\n",
       "   54,\n",
       "   56,\n",
       "   64,\n",
       "   68,\n",
       "   70,\n",
       "   72,\n",
       "   74,\n",
       "   76,\n",
       "   80,\n",
       "   84,\n",
       "   86,\n",
       "   88,\n",
       "   90,\n",
       "   92,\n",
       "   96,\n",
       "   100,\n",
       "   102,\n",
       "   104,\n",
       "   106,\n",
       "   108,\n",
       "   112,\n",
       "   116,\n",
       "   118,\n",
       "   120],\n",
       "  'beatfraction': ['1',\n",
       "   '1/2',\n",
       "   '1/2',\n",
       "   '3/4',\n",
       "   '1/4',\n",
       "   '1',\n",
       "   '1',\n",
       "   '1/2',\n",
       "   '1/2',\n",
       "   '1/2',\n",
       "   '1/2',\n",
       "   '1',\n",
       "   '1',\n",
       "   '1/2',\n",
       "   '1/2',\n",
       "   '1/2',\n",
       "   '1/2',\n",
       "   '1',\n",
       "   '1',\n",
       "   '1/2',\n",
       "   '1/2',\n",
       "   '1',\n",
       "   '1',\n",
       "   '1/2',\n",
       "   '1/2',\n",
       "   '1/2',\n",
       "   '1/2',\n",
       "   '1',\n",
       "   '1',\n",
       "   '1/2',\n",
       "   '1/2',\n",
       "   '1/2',\n",
       "   '1/2',\n",
       "   '1',\n",
       "   '1',\n",
       "   '1/2',\n",
       "   '1/2',\n",
       "   '1/2',\n",
       "   '1/2',\n",
       "   '1',\n",
       "   '1',\n",
       "   '1/2',\n",
       "   '1/2',\n",
       "   '3/2'],\n",
       "  'phrasepos': [0.0,\n",
       "   0.142857,\n",
       "   0.214286,\n",
       "   0.285714,\n",
       "   0.392857,\n",
       "   0.428571,\n",
       "   0.571429,\n",
       "   0.714286,\n",
       "   0.785714,\n",
       "   0.857143,\n",
       "   0.928571,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.166667,\n",
       "   0.25,\n",
       "   0.333333,\n",
       "   0.416667,\n",
       "   0.5,\n",
       "   0.666667,\n",
       "   0.833333,\n",
       "   0.916667,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.142857,\n",
       "   0.214286,\n",
       "   0.285714,\n",
       "   0.357143,\n",
       "   0.428571,\n",
       "   0.571429,\n",
       "   0.714286,\n",
       "   0.785714,\n",
       "   0.857143,\n",
       "   0.928571,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.166667,\n",
       "   0.25,\n",
       "   0.333333,\n",
       "   0.416667,\n",
       "   0.5,\n",
       "   0.666667,\n",
       "   0.833333,\n",
       "   0.916667,\n",
       "   1.0],\n",
       "  'phrase_ix': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   3,\n",
       "   3],\n",
       "  'phrase_end': [False,\n",
       "   False,\n",
       "   False,\n",
       "   False,\n",
       "   False,\n",
       "   False,\n",
       "   False,\n",
       "   False,\n",
       "   False,\n",
       "   False,\n",
       "   False,\n",
       "   True,\n",
       "   False,\n",
       "   False,\n",
       "   False,\n",
       "   False,\n",
       "   False,\n",
       "   False,\n",
       "   False,\n",
       "   False,\n",
       "   False,\n",
       "   True,\n",
       "   False,\n",
       "   False,\n",
       "   False,\n",
       "   False,\n",
       "   False,\n",
       "   False,\n",
       "   False,\n",
       "   False,\n",
       "   False,\n",
       "   False,\n",
       "   False,\n",
       "   True,\n",
       "   False,\n",
       "   False,\n",
       "   False,\n",
       "   False,\n",
       "   False,\n",
       "   False,\n",
       "   False,\n",
       "   False,\n",
       "   False,\n",
       "   True],\n",
       "  'songpos': [0.0,\n",
       "   0.03333333333333333,\n",
       "   0.05,\n",
       "   0.06666666666666667,\n",
       "   0.09166666666666666,\n",
       "   0.1,\n",
       "   0.13333333333333333,\n",
       "   0.16666666666666666,\n",
       "   0.18333333333333332,\n",
       "   0.2,\n",
       "   0.21666666666666667,\n",
       "   0.23333333333333334,\n",
       "   0.26666666666666666,\n",
       "   0.3,\n",
       "   0.31666666666666665,\n",
       "   0.3333333333333333,\n",
       "   0.35,\n",
       "   0.36666666666666664,\n",
       "   0.4,\n",
       "   0.43333333333333335,\n",
       "   0.45,\n",
       "   0.4666666666666667,\n",
       "   0.5333333333333333,\n",
       "   0.5666666666666667,\n",
       "   0.5833333333333334,\n",
       "   0.6,\n",
       "   0.6166666666666667,\n",
       "   0.6333333333333333,\n",
       "   0.6666666666666666,\n",
       "   0.7,\n",
       "   0.7166666666666667,\n",
       "   0.7333333333333333,\n",
       "   0.75,\n",
       "   0.7666666666666667,\n",
       "   0.8,\n",
       "   0.8333333333333334,\n",
       "   0.85,\n",
       "   0.8666666666666667,\n",
       "   0.8833333333333333,\n",
       "   0.9,\n",
       "   0.9333333333333333,\n",
       "   0.9666666666666667,\n",
       "   0.9833333333333333,\n",
       "   1.0],\n",
       "  'beatinsong': ['0',\n",
       "   '1',\n",
       "   '3/2',\n",
       "   '2',\n",
       "   '11/4',\n",
       "   '3',\n",
       "   '4',\n",
       "   '5',\n",
       "   '11/2',\n",
       "   '6',\n",
       "   '13/2',\n",
       "   '7',\n",
       "   '8',\n",
       "   '9',\n",
       "   '19/2',\n",
       "   '10',\n",
       "   '21/2',\n",
       "   '11',\n",
       "   '12',\n",
       "   '13',\n",
       "   '27/2',\n",
       "   '14',\n",
       "   '16',\n",
       "   '17',\n",
       "   '35/2',\n",
       "   '18',\n",
       "   '37/2',\n",
       "   '19',\n",
       "   '20',\n",
       "   '21',\n",
       "   '43/2',\n",
       "   '22',\n",
       "   '45/2',\n",
       "   '23',\n",
       "   '24',\n",
       "   '25',\n",
       "   '51/2',\n",
       "   '26',\n",
       "   '53/2',\n",
       "   '27',\n",
       "   '28',\n",
       "   '29',\n",
       "   '59/2',\n",
       "   '30'],\n",
       "  'beatinphrase': ['0',\n",
       "   '1',\n",
       "   '3/2',\n",
       "   '2',\n",
       "   '11/4',\n",
       "   '3',\n",
       "   '4',\n",
       "   '5',\n",
       "   '11/2',\n",
       "   '6',\n",
       "   '13/2',\n",
       "   '7',\n",
       "   '0',\n",
       "   '1',\n",
       "   '3/2',\n",
       "   '2',\n",
       "   '5/2',\n",
       "   '3',\n",
       "   '4',\n",
       "   '5',\n",
       "   '11/2',\n",
       "   '6',\n",
       "   '0',\n",
       "   '1',\n",
       "   '3/2',\n",
       "   '2',\n",
       "   '5/2',\n",
       "   '3',\n",
       "   '4',\n",
       "   '5',\n",
       "   '11/2',\n",
       "   '6',\n",
       "   '13/2',\n",
       "   '7',\n",
       "   '0',\n",
       "   '1',\n",
       "   '3/2',\n",
       "   '2',\n",
       "   '5/2',\n",
       "   '3',\n",
       "   '4',\n",
       "   '5',\n",
       "   '11/2',\n",
       "   '6'],\n",
       "  'beatinphrase_end': ['-6',\n",
       "   '-5',\n",
       "   '-9/2',\n",
       "   '-4',\n",
       "   '-13/4',\n",
       "   '-3',\n",
       "   '-2',\n",
       "   '-1',\n",
       "   '-1/2',\n",
       "   '0',\n",
       "   '1/2',\n",
       "   '1',\n",
       "   '-6',\n",
       "   '-5',\n",
       "   '-9/2',\n",
       "   '-4',\n",
       "   '-7/2',\n",
       "   '-3',\n",
       "   '-2',\n",
       "   '-1',\n",
       "   '-1/2',\n",
       "   '0',\n",
       "   '-6',\n",
       "   '-5',\n",
       "   '-9/2',\n",
       "   '-4',\n",
       "   '-7/2',\n",
       "   '-3',\n",
       "   '-2',\n",
       "   '-1',\n",
       "   '-1/2',\n",
       "   '0',\n",
       "   '1/2',\n",
       "   '1',\n",
       "   '-6',\n",
       "   '-5',\n",
       "   '-9/2',\n",
       "   '-4',\n",
       "   '-7/2',\n",
       "   '-3',\n",
       "   '-2',\n",
       "   '-1',\n",
       "   '-1/2',\n",
       "   '0'],\n",
       "  'IOI_frac': ['1',\n",
       "   '1/2',\n",
       "   '1/2',\n",
       "   '3/4',\n",
       "   '1/4',\n",
       "   '1',\n",
       "   '1',\n",
       "   '1/2',\n",
       "   '1/2',\n",
       "   '1/2',\n",
       "   '1/2',\n",
       "   '1',\n",
       "   '1',\n",
       "   '1/2',\n",
       "   '1/2',\n",
       "   '1/2',\n",
       "   '1/2',\n",
       "   '1',\n",
       "   '1',\n",
       "   '1/2',\n",
       "   '1/2',\n",
       "   '2',\n",
       "   '1',\n",
       "   '1/2',\n",
       "   '1/2',\n",
       "   '1/2',\n",
       "   '1/2',\n",
       "   '1',\n",
       "   '1',\n",
       "   '1/2',\n",
       "   '1/2',\n",
       "   '1/2',\n",
       "   '1/2',\n",
       "   '1',\n",
       "   '1',\n",
       "   '1/2',\n",
       "   '1/2',\n",
       "   '1/2',\n",
       "   '1/2',\n",
       "   '1',\n",
       "   '1',\n",
       "   '1/2',\n",
       "   '1/2',\n",
       "   '2'],\n",
       "  'IOI': [1.0,\n",
       "   0.5,\n",
       "   0.5,\n",
       "   0.75,\n",
       "   0.25,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.5,\n",
       "   0.5,\n",
       "   0.5,\n",
       "   0.5,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.5,\n",
       "   0.5,\n",
       "   0.5,\n",
       "   0.5,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.5,\n",
       "   0.5,\n",
       "   2.0,\n",
       "   1.0,\n",
       "   0.5,\n",
       "   0.5,\n",
       "   0.5,\n",
       "   0.5,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.5,\n",
       "   0.5,\n",
       "   0.5,\n",
       "   0.5,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.5,\n",
       "   0.5,\n",
       "   0.5,\n",
       "   0.5,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.5,\n",
       "   0.5,\n",
       "   2.0],\n",
       "  'IOR': [None,\n",
       "   0.5,\n",
       "   1.0,\n",
       "   1.5,\n",
       "   0.3333333333333333,\n",
       "   4.0,\n",
       "   1.0,\n",
       "   0.5,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   2.0,\n",
       "   1.0,\n",
       "   0.5,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   2.0,\n",
       "   1.0,\n",
       "   0.5,\n",
       "   1.0,\n",
       "   4.0,\n",
       "   0.5,\n",
       "   0.5,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   2.0,\n",
       "   1.0,\n",
       "   0.5,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   2.0,\n",
       "   1.0,\n",
       "   0.5,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   2.0,\n",
       "   1.0,\n",
       "   0.5,\n",
       "   1.0,\n",
       "   4.0],\n",
       "  'imacontour': [None,\n",
       "   '-',\n",
       "   '-',\n",
       "   '+',\n",
       "   '-',\n",
       "   '+',\n",
       "   '+',\n",
       "   '-',\n",
       "   '-',\n",
       "   '+',\n",
       "   '-',\n",
       "   '+',\n",
       "   '+',\n",
       "   '-',\n",
       "   '-',\n",
       "   '+',\n",
       "   '-',\n",
       "   '+',\n",
       "   '+',\n",
       "   '-',\n",
       "   '-',\n",
       "   '+',\n",
       "   '-',\n",
       "   '-',\n",
       "   '-',\n",
       "   '+',\n",
       "   '-',\n",
       "   '+',\n",
       "   '+',\n",
       "   '-',\n",
       "   '-',\n",
       "   '+',\n",
       "   '-',\n",
       "   '+',\n",
       "   '+',\n",
       "   '-',\n",
       "   '-',\n",
       "   '+',\n",
       "   '-',\n",
       "   '+',\n",
       "   '+',\n",
       "   '-',\n",
       "   '-',\n",
       "   '+'],\n",
       "  'pitch': ['E4',\n",
       "   'C4',\n",
       "   'A3',\n",
       "   'G3',\n",
       "   'C4',\n",
       "   'C4',\n",
       "   'D4',\n",
       "   'C4',\n",
       "   'D4',\n",
       "   'E4',\n",
       "   'A3',\n",
       "   'G3',\n",
       "   'G3',\n",
       "   'F#3',\n",
       "   'G3',\n",
       "   'A3',\n",
       "   'F4',\n",
       "   'E4',\n",
       "   'D4',\n",
       "   'E4',\n",
       "   'D4',\n",
       "   'G3',\n",
       "   'D4',\n",
       "   'E4',\n",
       "   'D4',\n",
       "   'C4',\n",
       "   'A3',\n",
       "   'G3',\n",
       "   'E4',\n",
       "   'F4',\n",
       "   'E4',\n",
       "   'A3',\n",
       "   'E4',\n",
       "   'D4',\n",
       "   'G3',\n",
       "   'A3',\n",
       "   'G3',\n",
       "   'G3',\n",
       "   'F4',\n",
       "   'E4',\n",
       "   'D4',\n",
       "   'A3',\n",
       "   'B3',\n",
       "   'C4'],\n",
       "  'contour3': [None,\n",
       "   '-',\n",
       "   '-',\n",
       "   '-',\n",
       "   '+',\n",
       "   '=',\n",
       "   '+',\n",
       "   '-',\n",
       "   '+',\n",
       "   '+',\n",
       "   '-',\n",
       "   '-',\n",
       "   '=',\n",
       "   '-',\n",
       "   '+',\n",
       "   '+',\n",
       "   '+',\n",
       "   '-',\n",
       "   '-',\n",
       "   '+',\n",
       "   '-',\n",
       "   '-',\n",
       "   '+',\n",
       "   '+',\n",
       "   '-',\n",
       "   '-',\n",
       "   '-',\n",
       "   '-',\n",
       "   '+',\n",
       "   '+',\n",
       "   '-',\n",
       "   '-',\n",
       "   '+',\n",
       "   '-',\n",
       "   '-',\n",
       "   '+',\n",
       "   '-',\n",
       "   '=',\n",
       "   '+',\n",
       "   '-',\n",
       "   '-',\n",
       "   '-',\n",
       "   '+',\n",
       "   '+'],\n",
       "  'contour5': [None,\n",
       "   '--',\n",
       "   '--',\n",
       "   '-',\n",
       "   '++',\n",
       "   '=',\n",
       "   '+',\n",
       "   '-',\n",
       "   '+',\n",
       "   '+',\n",
       "   '--',\n",
       "   '-',\n",
       "   '=',\n",
       "   '-',\n",
       "   '+',\n",
       "   '+',\n",
       "   '++',\n",
       "   '-',\n",
       "   '-',\n",
       "   '+',\n",
       "   '-',\n",
       "   '--',\n",
       "   '++',\n",
       "   '+',\n",
       "   '-',\n",
       "   '-',\n",
       "   '--',\n",
       "   '-',\n",
       "   '++',\n",
       "   '+',\n",
       "   '-',\n",
       "   '--',\n",
       "   '++',\n",
       "   '-',\n",
       "   '--',\n",
       "   '+',\n",
       "   '-',\n",
       "   '=',\n",
       "   '++',\n",
       "   '-',\n",
       "   '-',\n",
       "   '--',\n",
       "   '+',\n",
       "   '+'],\n",
       "  'beatstrength': [1.0,\n",
       "   0.5,\n",
       "   0.25,\n",
       "   1.0,\n",
       "   0.125,\n",
       "   0.5,\n",
       "   1.0,\n",
       "   0.5,\n",
       "   0.25,\n",
       "   1.0,\n",
       "   0.25,\n",
       "   0.5,\n",
       "   1.0,\n",
       "   0.5,\n",
       "   0.25,\n",
       "   1.0,\n",
       "   0.25,\n",
       "   0.5,\n",
       "   1.0,\n",
       "   0.5,\n",
       "   0.25,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.5,\n",
       "   0.25,\n",
       "   1.0,\n",
       "   0.25,\n",
       "   0.5,\n",
       "   1.0,\n",
       "   0.5,\n",
       "   0.25,\n",
       "   1.0,\n",
       "   0.25,\n",
       "   0.5,\n",
       "   1.0,\n",
       "   0.5,\n",
       "   0.25,\n",
       "   1.0,\n",
       "   0.25,\n",
       "   0.5,\n",
       "   1.0,\n",
       "   0.5,\n",
       "   0.25,\n",
       "   1.0],\n",
       "  'beat_str': ['1',\n",
       "   '2',\n",
       "   '2',\n",
       "   '1',\n",
       "   '1',\n",
       "   '2',\n",
       "   '1',\n",
       "   '2',\n",
       "   '2',\n",
       "   '1',\n",
       "   '1',\n",
       "   '2',\n",
       "   '1',\n",
       "   '2',\n",
       "   '2',\n",
       "   '1',\n",
       "   '1',\n",
       "   '2',\n",
       "   '1',\n",
       "   '2',\n",
       "   '2',\n",
       "   '1',\n",
       "   '1',\n",
       "   '2',\n",
       "   '2',\n",
       "   '1',\n",
       "   '1',\n",
       "   '2',\n",
       "   '1',\n",
       "   '2',\n",
       "   '2',\n",
       "   '1',\n",
       "   '1',\n",
       "   '2',\n",
       "   '1',\n",
       "   '2',\n",
       "   '2',\n",
       "   '1',\n",
       "   '1',\n",
       "   '2',\n",
       "   '1',\n",
       "   '2',\n",
       "   '2',\n",
       "   '1'],\n",
       "  'beat_fraction_str': ['0',\n",
       "   '0',\n",
       "   '1/2',\n",
       "   '0',\n",
       "   '3/4',\n",
       "   '0',\n",
       "   '0',\n",
       "   '0',\n",
       "   '1/2',\n",
       "   '0',\n",
       "   '1/2',\n",
       "   '0',\n",
       "   '0',\n",
       "   '0',\n",
       "   '1/2',\n",
       "   '0',\n",
       "   '1/2',\n",
       "   '0',\n",
       "   '0',\n",
       "   '0',\n",
       "   '1/2',\n",
       "   '0',\n",
       "   '0',\n",
       "   '0',\n",
       "   '1/2',\n",
       "   '0',\n",
       "   '1/2',\n",
       "   '0',\n",
       "   '0',\n",
       "   '0',\n",
       "   '1/2',\n",
       "   '0',\n",
       "   '1/2',\n",
       "   '0',\n",
       "   '0',\n",
       "   '0',\n",
       "   '1/2',\n",
       "   '0',\n",
       "   '1/2',\n",
       "   '0',\n",
       "   '0',\n",
       "   '0',\n",
       "   '1/2',\n",
       "   '0'],\n",
       "  'beat': [1.0,\n",
       "   2.0,\n",
       "   2.5,\n",
       "   1.0,\n",
       "   1.75,\n",
       "   2.0,\n",
       "   1.0,\n",
       "   2.0,\n",
       "   2.5,\n",
       "   1.0,\n",
       "   1.5,\n",
       "   2.0,\n",
       "   1.0,\n",
       "   2.0,\n",
       "   2.5,\n",
       "   1.0,\n",
       "   1.5,\n",
       "   2.0,\n",
       "   1.0,\n",
       "   2.0,\n",
       "   2.5,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   2.0,\n",
       "   2.5,\n",
       "   1.0,\n",
       "   1.5,\n",
       "   2.0,\n",
       "   1.0,\n",
       "   2.0,\n",
       "   2.5,\n",
       "   1.0,\n",
       "   1.5,\n",
       "   2.0,\n",
       "   1.0,\n",
       "   2.0,\n",
       "   2.5,\n",
       "   1.0,\n",
       "   1.5,\n",
       "   2.0,\n",
       "   1.0,\n",
       "   2.0,\n",
       "   2.5,\n",
       "   1.0],\n",
       "  'timesignature': ['2/4',\n",
       "   '2/4',\n",
       "   '2/4',\n",
       "   '2/4',\n",
       "   '2/4',\n",
       "   '2/4',\n",
       "   '2/4',\n",
       "   '2/4',\n",
       "   '2/4',\n",
       "   '2/4',\n",
       "   '2/4',\n",
       "   '2/4',\n",
       "   '2/4',\n",
       "   '2/4',\n",
       "   '2/4',\n",
       "   '2/4',\n",
       "   '2/4',\n",
       "   '2/4',\n",
       "   '2/4',\n",
       "   '2/4',\n",
       "   '2/4',\n",
       "   '2/4',\n",
       "   '2/4',\n",
       "   '2/4',\n",
       "   '2/4',\n",
       "   '2/4',\n",
       "   '2/4',\n",
       "   '2/4',\n",
       "   '2/4',\n",
       "   '2/4',\n",
       "   '2/4',\n",
       "   '2/4',\n",
       "   '2/4',\n",
       "   '2/4',\n",
       "   '2/4',\n",
       "   '2/4',\n",
       "   '2/4',\n",
       "   '2/4',\n",
       "   '2/4',\n",
       "   '2/4',\n",
       "   '2/4',\n",
       "   '2/4',\n",
       "   '2/4',\n",
       "   '2/4'],\n",
       "  'gpr2a_Frankland': [None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   0.25,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   0.125],\n",
       "  'gpr2b_Frankland': [None,\n",
       "   None,\n",
       "   None,\n",
       "   0.5,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None],\n",
       "  'gpr3a_Frankland': [None,\n",
       "   None,\n",
       "   None,\n",
       "   0.8,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   0.7142857142857143,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   0.8125,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   0.33333333333333337,\n",
       "   None,\n",
       "   0.8333333333333334,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   0.7142857142857143,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   0.95,\n",
       "   None,\n",
       "   None,\n",
       "   0.6,\n",
       "   None,\n",
       "   None,\n",
       "   None],\n",
       "  'gpr3d_Frankland': [None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   0.5,\n",
       "   None,\n",
       "   0.0,\n",
       "   None,\n",
       "   0.5,\n",
       "   None,\n",
       "   0.5,\n",
       "   None,\n",
       "   0.0,\n",
       "   None,\n",
       "   0.5,\n",
       "   None,\n",
       "   0.5,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   None,\n",
       "   0.0,\n",
       "   None,\n",
       "   0.5,\n",
       "   None,\n",
       "   0.5,\n",
       "   None,\n",
       "   0.0,\n",
       "   None,\n",
       "   0.5,\n",
       "   None,\n",
       "   0.5,\n",
       "   None,\n",
       "   0.0,\n",
       "   None,\n",
       "   0.5,\n",
       "   None,\n",
       "   0.5,\n",
       "   None,\n",
       "   None,\n",
       "   None],\n",
       "  'gpr_Frankland_sum': [0,\n",
       "   0,\n",
       "   0,\n",
       "   1.3,\n",
       "   0,\n",
       "   0,\n",
       "   0.5,\n",
       "   0,\n",
       "   0,\n",
       "   0.7142857142857143,\n",
       "   0.5,\n",
       "   0,\n",
       "   0.5,\n",
       "   0,\n",
       "   0,\n",
       "   0.8125,\n",
       "   0.5,\n",
       "   0,\n",
       "   0.5,\n",
       "   0,\n",
       "   0,\n",
       "   0.25,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0.33333333333333337,\n",
       "   0.5,\n",
       "   0.8333333333333334,\n",
       "   0.5,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0.5,\n",
       "   0.7142857142857143,\n",
       "   0.5,\n",
       "   0,\n",
       "   0,\n",
       "   0.95,\n",
       "   0.5,\n",
       "   0,\n",
       "   1.1,\n",
       "   0,\n",
       "   0,\n",
       "   0.125],\n",
       "  'lbdm_spitch': [None,\n",
       "   0.04993997599039616,\n",
       "   0.062424969987995196,\n",
       "   0.3433373349339736,\n",
       "   0.0,\n",
       "   0.06554621848739496,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.059587471352177235,\n",
       "   0.41711229946524064,\n",
       "   0.1251336898395722,\n",
       "   0.0,\n",
       "   0.021848739495798318,\n",
       "   0.013109243697478993,\n",
       "   0.09176470588235294,\n",
       "   0.5958747135217723,\n",
       "   0.05482047364400306,\n",
       "   0.026218487394957985,\n",
       "   0.0,\n",
       "   0.059587471352177235,\n",
       "   0.20855614973262032,\n",
       "   0.20855614973262032,\n",
       "   0.059587471352177235,\n",
       "   0.0,\n",
       "   0.01872749099639856,\n",
       "   0.05618247298919568,\n",
       "   0.08931572629051622,\n",
       "   0.7109243697478991,\n",
       "   0.043697478991596636,\n",
       "   0.03932773109243697,\n",
       "   0.27529411764705886,\n",
       "   0.20855614973262032,\n",
       "   0.11917494270435447,\n",
       "   0.41711229946524064,\n",
       "   0.059587471352177235,\n",
       "   0.06554621848739496,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.05848739495798319,\n",
       "   0.06991596638655463,\n",
       "   0.2184873949579832,\n",
       "   0.06991596638655463,\n",
       "   None,\n",
       "   None],\n",
       "  'lbdm_sioi': [None,\n",
       "   0.08928571428571427,\n",
       "   0.053571428571428575,\n",
       "   0.28124999999999994,\n",
       "   0.14732142857142858,\n",
       "   0.3214285714285714,\n",
       "   0.17857142857142855,\n",
       "   0.08928571428571427,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.08928571428571427,\n",
       "   0.17857142857142855,\n",
       "   0.17857142857142855,\n",
       "   0.08928571428571427,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.08928571428571427,\n",
       "   0.17857142857142855,\n",
       "   0.17857142857142855,\n",
       "   0.08928571428571427,\n",
       "   0.1607142857142857,\n",
       "   1.0,\n",
       "   0.3571428571428571,\n",
       "   0.08928571428571427,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.08928571428571427,\n",
       "   0.17857142857142855,\n",
       "   0.17857142857142855,\n",
       "   0.08928571428571427,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.08928571428571427,\n",
       "   0.17857142857142855,\n",
       "   0.17857142857142855,\n",
       "   0.08928571428571427,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.08928571428571427,\n",
       "   0.17857142857142855,\n",
       "   0.17857142857142855,\n",
       "   0.08928571428571427,\n",
       "   None,\n",
       "   None],\n",
       "  'lbdm_srest': [None,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   None,\n",
       "   None],\n",
       "  'lbdm_rpitch': [None,\n",
       "   0.1111111111111111,\n",
       "   0.14285714285714285,\n",
       "   0.3333333333333333,\n",
       "   0.7142857142857143,\n",
       "   0.5,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.45454545454545453,\n",
       "   0.45454545454545453,\n",
       "   0.5,\n",
       "   0.3333333333333333,\n",
       "   0.0,\n",
       "   0.2,\n",
       "   0.5,\n",
       "   0.6363636363636364,\n",
       "   0.2,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.45454545454545453,\n",
       "   0.0,\n",
       "   0.45454545454545453,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.14285714285714285,\n",
       "   0.14285714285714285,\n",
       "   0.5384615384615384,\n",
       "   0.6666666666666666,\n",
       "   0.0,\n",
       "   0.6,\n",
       "   0.0,\n",
       "   0.45454545454545453,\n",
       "   0.45454545454545453,\n",
       "   0.45454545454545453,\n",
       "   0.0,\n",
       "   0.5,\n",
       "   0.8333333333333334,\n",
       "   0.6923076923076923,\n",
       "   0.2,\n",
       "   0.3333333333333333,\n",
       "   0.3333333333333333,\n",
       "   0.2,\n",
       "   None],\n",
       "  'lbdm_rioi': [None,\n",
       "   0.3333333333333333,\n",
       "   0.0,\n",
       "   0.2,\n",
       "   0.5,\n",
       "   0.6,\n",
       "   0.0,\n",
       "   0.3333333333333333,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.3333333333333333,\n",
       "   0.0,\n",
       "   0.3333333333333333,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.3333333333333333,\n",
       "   0.0,\n",
       "   0.3333333333333333,\n",
       "   0.0,\n",
       "   0.6,\n",
       "   0.3333333333333333,\n",
       "   0.3333333333333333,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.3333333333333333,\n",
       "   0.0,\n",
       "   0.3333333333333333,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.3333333333333333,\n",
       "   0.0,\n",
       "   0.3333333333333333,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.3333333333333333,\n",
       "   0.0,\n",
       "   0.3333333333333333,\n",
       "   0.0,\n",
       "   None],\n",
       "  'lbdm_rrest': [None,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   1.0,\n",
       "   1.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   None],\n",
       "  'lbdm_boundarystrength': [None,\n",
       "   0.057127851140456175,\n",
       "   0.04239195678271308,\n",
       "   0.22645933373349336,\n",
       "   0.07366071428571429,\n",
       "   0.17710084033613444,\n",
       "   0.08928571428571427,\n",
       "   0.04464285714285714,\n",
       "   0.014896867838044309,\n",
       "   0.10427807486631016,\n",
       "   0.0759262796027502,\n",
       "   0.08928571428571427,\n",
       "   0.09474789915966385,\n",
       "   0.04792016806722688,\n",
       "   0.022941176470588236,\n",
       "   0.1489686783804431,\n",
       "   0.0583479755538579,\n",
       "   0.09584033613445377,\n",
       "   0.08928571428571427,\n",
       "   0.059539724980901446,\n",
       "   0.13249618029029792,\n",
       "   0.8021390374331551,\n",
       "   0.19346829640947286,\n",
       "   0.04464285714285714,\n",
       "   0.00468187274909964,\n",
       "   0.01404561824729892,\n",
       "   0.06697178871548619,\n",
       "   0.267016806722689,\n",
       "   0.10021008403361344,\n",
       "   0.05447478991596638,\n",
       "   0.06882352941176471,\n",
       "   0.05213903743315508,\n",
       "   0.07443659281894575,\n",
       "   0.19356378915202443,\n",
       "   0.10418258212375858,\n",
       "   0.061029411764705874,\n",
       "   0.0,\n",
       "   0.25,\n",
       "   0.059264705882352935,\n",
       "   0.10676470588235293,\n",
       "   0.14390756302521007,\n",
       "   0.06212184873949579,\n",
       "   None,\n",
       "   None],\n",
       "  'durationcontour': [None,\n",
       "   '-',\n",
       "   '=',\n",
       "   '+',\n",
       "   '-',\n",
       "   '+',\n",
       "   '=',\n",
       "   '-',\n",
       "   '=',\n",
       "   '=',\n",
       "   '=',\n",
       "   '+',\n",
       "   '=',\n",
       "   '-',\n",
       "   '=',\n",
       "   '=',\n",
       "   '=',\n",
       "   '+',\n",
       "   '=',\n",
       "   '-',\n",
       "   '=',\n",
       "   '+',\n",
       "   '=',\n",
       "   '-',\n",
       "   '=',\n",
       "   '=',\n",
       "   '=',\n",
       "   '+',\n",
       "   '=',\n",
       "   '-',\n",
       "   '=',\n",
       "   '=',\n",
       "   '=',\n",
       "   '+',\n",
       "   '=',\n",
       "   '-',\n",
       "   '=',\n",
       "   '=',\n",
       "   '=',\n",
       "   '+',\n",
       "   '=',\n",
       "   '-',\n",
       "   '=',\n",
       "   '+'],\n",
       "  'IOR_frac': [None,\n",
       "   '1/2',\n",
       "   '1',\n",
       "   '3/2',\n",
       "   '1/3',\n",
       "   '4',\n",
       "   '1',\n",
       "   '1/2',\n",
       "   '1',\n",
       "   '1',\n",
       "   '1',\n",
       "   '2',\n",
       "   '1',\n",
       "   '1/2',\n",
       "   '1',\n",
       "   '1',\n",
       "   '1',\n",
       "   '2',\n",
       "   '1',\n",
       "   '1/2',\n",
       "   '1',\n",
       "   '4',\n",
       "   '1/2',\n",
       "   '1/2',\n",
       "   '1',\n",
       "   '1',\n",
       "   '1',\n",
       "   '2',\n",
       "   '1',\n",
       "   '1/2',\n",
       "   '1',\n",
       "   '1',\n",
       "   '1',\n",
       "   '2',\n",
       "   '1',\n",
       "   '1/2',\n",
       "   '1',\n",
       "   '1',\n",
       "   '1',\n",
       "   '2',\n",
       "   '1',\n",
       "   '1/2',\n",
       "   '1',\n",
       "   '4']},\n",
       " 'ann_bgcorpus': True}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item = seqs.__next__()\n",
    "item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34ea2d16-c775-41f8-8409-c8d309217b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-level keys in the sequence item:\n",
      "dict_keys(['id', 'tunefamily', 'year', 'tunefamily_full', 'type', 'freemeter', 'features', 'ann_bgcorpus'])\n",
      "Length: 8\n",
      "\n",
      "Keys in the 'features' dictionary:\n",
      "dict_keys(['scaledegree', 'scaledegreespecifier', 'tonic', 'mode', 'metriccontour', 'imaweight', 'pitch40', 'midipitch', 'diatonicpitch', 'diatonicinterval', 'chromaticinterval', 'pitchproximity', 'pitchreversal', 'nextisrest', 'restduration_frac', 'duration', 'duration_frac', 'duration_fullname', 'onsettick', 'beatfraction', 'phrasepos', 'phrase_ix', 'phrase_end', 'songpos', 'beatinsong', 'beatinphrase', 'beatinphrase_end', 'IOI_frac', 'IOI', 'IOR', 'imacontour', 'pitch', 'contour3', 'contour5', 'beatstrength', 'beat_str', 'beat_fraction_str', 'beat', 'timesignature', 'gpr2a_Frankland', 'gpr2b_Frankland', 'gpr3a_Frankland', 'gpr3d_Frankland', 'gpr_Frankland_sum', 'lbdm_spitch', 'lbdm_sioi', 'lbdm_srest', 'lbdm_rpitch', 'lbdm_rioi', 'lbdm_rrest', 'lbdm_boundarystrength', 'durationcontour', 'IOR_frac'])\n",
      "Length: 53\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Retrieve and print the keys of the current sequence item\n",
    "# This shows the top-level structure of the sequence object\n",
    "print(f\"Top-level keys in the sequence item:\\n{item.keys()}\")\n",
    "print(f\"Length: {len(item.keys())}\\n\")\n",
    "\n",
    "# Retrieve and print the keys of the 'features' dictionary within the sequence item\n",
    "# This helps to understand the available feature data\n",
    "print(f\"Keys in the 'features' dictionary:\\n{item['features'].keys()}\")\n",
    "print(f\"Length: {len(item['features'].keys())}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16cc1133-8aef-4784-8575-92e2a85edf27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 18108 sequences.\n",
      "CPU times: user 7.16 s, sys: 336 ms, total: 7.49 s\n",
      "Wall time: 7.59 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "phrase_data = []\n",
    "for ii, x in enumerate(seqs):\n",
    "    phrase_data.append({\n",
    "        'id': x['id'],          # Add the sequence ID to the dictionary\n",
    "        **x['features']         # Unpack all feature data into the dictionary\n",
    "    })\n",
    "\n",
    "print(f\"Processed {len(phrase_data)} sequences.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89588982-6256-4339-b77e-e07a0114752e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Rows: 18108    Number of Columns: 62\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>scaledegree</th>\n",
       "      <th>scaledegreespecifier</th>\n",
       "      <th>tonic</th>\n",
       "      <th>mode</th>\n",
       "      <th>metriccontour</th>\n",
       "      <th>imaweight</th>\n",
       "      <th>pitch40</th>\n",
       "      <th>midipitch</th>\n",
       "      <th>diatonicpitch</th>\n",
       "      <th>...</th>\n",
       "      <th>durationcontour</th>\n",
       "      <th>IOR_frac</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>noncontentword</th>\n",
       "      <th>wordend</th>\n",
       "      <th>phoneme</th>\n",
       "      <th>rhymes</th>\n",
       "      <th>rhymescontentwords</th>\n",
       "      <th>wordstress</th>\n",
       "      <th>melismastate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NLB125815_01</td>\n",
       "      <td>[5, 5, 6, 5, 4, 3, 1, 3, 3, 3, 3, 6, 5, 5, 6, ...</td>\n",
       "      <td>[P, A, M, P, P, M, P, M, M, M, M, M, P, P, M, ...</td>\n",
       "      <td>[F, F, F, F, F, F, F, F, F, F, F, F, F, F, F, ...</td>\n",
       "      <td>[major, major, major, major, major, major, maj...</td>\n",
       "      <td>[None, -, +, -, +, -, +, -, -, +, -, +, +, -, ...</td>\n",
       "      <td>[0.236646, 0.015528, 0.913043, 0.204348, 0.392...</td>\n",
       "      <td>[163, 164, 169, 163, 157, 152, 140, 152, 152, ...</td>\n",
       "      <td>[72, 73, 74, 72, 70, 69, 65, 69, 69, 69, 69, 7...</td>\n",
       "      <td>[32, 32, 33, 32, 31, 30, 28, 30, 30, 30, 30, 3...</td>\n",
       "      <td>...</td>\n",
       "      <td>[None, -, +, =, =, =, -, -, =, +, =, +, -, -, ...</td>\n",
       "      <td>[None, 1/3, 4, 1, 1, 1, 1/2, 1/2, 1, 2, 1, 4, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NLB125817_01</td>\n",
       "      <td>[5, 5, 5, 1, 5, 3, 2, 5, 2, 3, 2, 1, 2, 3, 4, ...</td>\n",
       "      <td>[P, P, P, P, P, M, M, P, M, M, M, P, M, M, P, ...</td>\n",
       "      <td>[C, C, C, C, C, C, C, C, C, C, C, C, C, C, C, ...</td>\n",
       "      <td>[major, major, major, major, major, major, maj...</td>\n",
       "      <td>[None, +, -, +, -, +, -, +, -, +, -, +, -, +, ...</td>\n",
       "      <td>[0.246883, 0.306733, 0.169576, 0.780549, 0.349...</td>\n",
       "      <td>[146, 146, 146, 163, 146, 175, 169, 146, 169, ...</td>\n",
       "      <td>[67, 67, 67, 72, 67, 76, 74, 67, 74, 76, 74, 7...</td>\n",
       "      <td>[32, 32, 32, 35, 32, 37, 36, 32, 36, 37, 36, 3...</td>\n",
       "      <td>...</td>\n",
       "      <td>[None, =, =, +, -, +, -, +, -, +, -, =, =, =, ...</td>\n",
       "      <td>[None, 1, 1, 3, 1/3, 3, 1/3, 6, 1/3, 3/2, 1/3,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NLB125818_01</td>\n",
       "      <td>[1, 1, 1, 1, 3, 2, 1, 7, 2, 2, 5, 4, 3, 4, 3, ...</td>\n",
       "      <td>[P, P, P, P, m, M, P, m, M, M, P, P, m, P, m, ...</td>\n",
       "      <td>[C, C, C, C, C, C, C, C, C, C, C, C, C, C, C, ...</td>\n",
       "      <td>[minor, minor, minor, minor, minor, minor, min...</td>\n",
       "      <td>[None, +, -, +, +, -, -, +, -, -, +, -, +, -, ...</td>\n",
       "      <td>[0.080378, 0.617021, 0.202128, 0.361702, 0.320...</td>\n",
       "      <td>[163, 163, 163, 163, 174, 169, 163, 157, 169, ...</td>\n",
       "      <td>[72, 72, 72, 72, 75, 74, 72, 70, 74, 74, 79, 7...</td>\n",
       "      <td>[35, 35, 35, 35, 37, 36, 35, 34, 36, 36, 39, 3...</td>\n",
       "      <td>...</td>\n",
       "      <td>[None, =, =, +, =, -, =, +, -, =, +, -, +, -, ...</td>\n",
       "      <td>[None, 1, 1, 2, 1, 1/2, 1, 2, 1/2, 1, 3, 1/3, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NLB125822_01</td>\n",
       "      <td>[5, 5, 5, 5, 5, 5, 5, 3, 3, 3, 3, 3, 3, 3, 3, ...</td>\n",
       "      <td>[P, P, P, P, P, P, P, M, M, M, M, M, M, M, M, ...</td>\n",
       "      <td>[F, F, F, F, F, F, F, F, F, F, F, F, F, F, F, ...</td>\n",
       "      <td>[major, major, major, major, major, major, maj...</td>\n",
       "      <td>[None, -, -, +, -, -, +, -, +, +, -, -, +, -, ...</td>\n",
       "      <td>[0.971634, 0.069592, 0.005484, 0.783094, 0.071...</td>\n",
       "      <td>[163, 163, 163, 163, 163, 163, 163, 152, 152, ...</td>\n",
       "      <td>[72, 72, 72, 72, 72, 72, 72, 69, 69, 69, 69, 6...</td>\n",
       "      <td>[32, 32, 32, 32, 32, 32, 32, 30, 30, 30, 30, 3...</td>\n",
       "      <td>...</td>\n",
       "      <td>[None, -, =, +, -, =, +, =, +, -, -, =, +, -, ...</td>\n",
       "      <td>[None, 1/2, 1, 2, 1/2, 1, 2, 1, 2, 1/2, 1/2, 1...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NLB125823_01</td>\n",
       "      <td>[3, 4, 4, 4, 5, 1, 1, 1, 2, 1, 2, 3, 4, 3, 2, ...</td>\n",
       "      <td>[M, P, P, P, P, P, P, P, M, P, M, M, P, M, M, ...</td>\n",
       "      <td>[G, G, G, G, G, G, G, G, G, G, G, G, G, G, G, ...</td>\n",
       "      <td>[major, major, major, major, major, major, maj...</td>\n",
       "      <td>[None, -, -, =, +, -, +, -, +, -, +, +, -, =, ...</td>\n",
       "      <td>[0.779032, 0.627419, 0.214516, 0.133871, 0.906...</td>\n",
       "      <td>[158, 163, 163, 163, 169, 186, 146, 146, 152, ...</td>\n",
       "      <td>[71, 72, 72, 72, 74, 79, 67, 67, 69, 67, 69, 7...</td>\n",
       "      <td>[30, 31, 31, 31, 32, 35, 28, 28, 29, 28, 29, 3...</td>\n",
       "      <td>...</td>\n",
       "      <td>[None, -, =, =, +, =, -, -, +, -, +, =, =, =, ...</td>\n",
       "      <td>[None, 1/3, 1, 1, 3, 1, 2/3, 1/2, 3/2, 1/3, 2,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                        scaledegree  \\\n",
       "0  NLB125815_01  [5, 5, 6, 5, 4, 3, 1, 3, 3, 3, 3, 6, 5, 5, 6, ...   \n",
       "1  NLB125817_01  [5, 5, 5, 1, 5, 3, 2, 5, 2, 3, 2, 1, 2, 3, 4, ...   \n",
       "2  NLB125818_01  [1, 1, 1, 1, 3, 2, 1, 7, 2, 2, 5, 4, 3, 4, 3, ...   \n",
       "3  NLB125822_01  [5, 5, 5, 5, 5, 5, 5, 3, 3, 3, 3, 3, 3, 3, 3, ...   \n",
       "4  NLB125823_01  [3, 4, 4, 4, 5, 1, 1, 1, 2, 1, 2, 3, 4, 3, 2, ...   \n",
       "\n",
       "                                scaledegreespecifier  \\\n",
       "0  [P, A, M, P, P, M, P, M, M, M, M, M, P, P, M, ...   \n",
       "1  [P, P, P, P, P, M, M, P, M, M, M, P, M, M, P, ...   \n",
       "2  [P, P, P, P, m, M, P, m, M, M, P, P, m, P, m, ...   \n",
       "3  [P, P, P, P, P, P, P, M, M, M, M, M, M, M, M, ...   \n",
       "4  [M, P, P, P, P, P, P, P, M, P, M, M, P, M, M, ...   \n",
       "\n",
       "                                               tonic  \\\n",
       "0  [F, F, F, F, F, F, F, F, F, F, F, F, F, F, F, ...   \n",
       "1  [C, C, C, C, C, C, C, C, C, C, C, C, C, C, C, ...   \n",
       "2  [C, C, C, C, C, C, C, C, C, C, C, C, C, C, C, ...   \n",
       "3  [F, F, F, F, F, F, F, F, F, F, F, F, F, F, F, ...   \n",
       "4  [G, G, G, G, G, G, G, G, G, G, G, G, G, G, G, ...   \n",
       "\n",
       "                                                mode  \\\n",
       "0  [major, major, major, major, major, major, maj...   \n",
       "1  [major, major, major, major, major, major, maj...   \n",
       "2  [minor, minor, minor, minor, minor, minor, min...   \n",
       "3  [major, major, major, major, major, major, maj...   \n",
       "4  [major, major, major, major, major, major, maj...   \n",
       "\n",
       "                                       metriccontour  \\\n",
       "0  [None, -, +, -, +, -, +, -, -, +, -, +, +, -, ...   \n",
       "1  [None, +, -, +, -, +, -, +, -, +, -, +, -, +, ...   \n",
       "2  [None, +, -, +, +, -, -, +, -, -, +, -, +, -, ...   \n",
       "3  [None, -, -, +, -, -, +, -, +, +, -, -, +, -, ...   \n",
       "4  [None, -, -, =, +, -, +, -, +, -, +, +, -, =, ...   \n",
       "\n",
       "                                           imaweight  \\\n",
       "0  [0.236646, 0.015528, 0.913043, 0.204348, 0.392...   \n",
       "1  [0.246883, 0.306733, 0.169576, 0.780549, 0.349...   \n",
       "2  [0.080378, 0.617021, 0.202128, 0.361702, 0.320...   \n",
       "3  [0.971634, 0.069592, 0.005484, 0.783094, 0.071...   \n",
       "4  [0.779032, 0.627419, 0.214516, 0.133871, 0.906...   \n",
       "\n",
       "                                             pitch40  \\\n",
       "0  [163, 164, 169, 163, 157, 152, 140, 152, 152, ...   \n",
       "1  [146, 146, 146, 163, 146, 175, 169, 146, 169, ...   \n",
       "2  [163, 163, 163, 163, 174, 169, 163, 157, 169, ...   \n",
       "3  [163, 163, 163, 163, 163, 163, 163, 152, 152, ...   \n",
       "4  [158, 163, 163, 163, 169, 186, 146, 146, 152, ...   \n",
       "\n",
       "                                           midipitch  \\\n",
       "0  [72, 73, 74, 72, 70, 69, 65, 69, 69, 69, 69, 7...   \n",
       "1  [67, 67, 67, 72, 67, 76, 74, 67, 74, 76, 74, 7...   \n",
       "2  [72, 72, 72, 72, 75, 74, 72, 70, 74, 74, 79, 7...   \n",
       "3  [72, 72, 72, 72, 72, 72, 72, 69, 69, 69, 69, 6...   \n",
       "4  [71, 72, 72, 72, 74, 79, 67, 67, 69, 67, 69, 7...   \n",
       "\n",
       "                                       diatonicpitch  ...  \\\n",
       "0  [32, 32, 33, 32, 31, 30, 28, 30, 30, 30, 30, 3...  ...   \n",
       "1  [32, 32, 32, 35, 32, 37, 36, 32, 36, 37, 36, 3...  ...   \n",
       "2  [35, 35, 35, 35, 37, 36, 35, 34, 36, 36, 39, 3...  ...   \n",
       "3  [32, 32, 32, 32, 32, 32, 32, 30, 30, 30, 30, 3...  ...   \n",
       "4  [30, 31, 31, 31, 32, 35, 28, 28, 29, 28, 29, 3...  ...   \n",
       "\n",
       "                                     durationcontour  \\\n",
       "0  [None, -, +, =, =, =, -, -, =, +, =, +, -, -, ...   \n",
       "1  [None, =, =, +, -, +, -, +, -, +, -, =, =, =, ...   \n",
       "2  [None, =, =, +, =, -, =, +, -, =, +, -, +, -, ...   \n",
       "3  [None, -, =, +, -, =, +, =, +, -, -, =, +, -, ...   \n",
       "4  [None, -, =, =, +, =, -, -, +, -, +, =, =, =, ...   \n",
       "\n",
       "                                            IOR_frac lyrics noncontentword  \\\n",
       "0  [None, 1/3, 4, 1, 1, 1, 1/2, 1/2, 1, 2, 1, 4, ...    NaN            NaN   \n",
       "1  [None, 1, 1, 3, 1/3, 3, 1/3, 6, 1/3, 3/2, 1/3,...    NaN            NaN   \n",
       "2  [None, 1, 1, 2, 1, 1/2, 1, 2, 1/2, 1, 3, 1/3, ...    NaN            NaN   \n",
       "3  [None, 1/2, 1, 2, 1/2, 1, 2, 1, 2, 1/2, 1/2, 1...    NaN            NaN   \n",
       "4  [None, 1/3, 1, 1, 3, 1, 2/3, 1/2, 3/2, 1/3, 2,...    NaN            NaN   \n",
       "\n",
       "  wordend phoneme rhymes rhymescontentwords wordstress melismastate  \n",
       "0     NaN     NaN    NaN                NaN        NaN          NaN  \n",
       "1     NaN     NaN    NaN                NaN        NaN          NaN  \n",
       "2     NaN     NaN    NaN                NaN        NaN          NaN  \n",
       "3     NaN     NaN    NaN                NaN        NaN          NaN  \n",
       "4     NaN     NaN    NaN                NaN        NaN          NaN  \n",
       "\n",
       "[5 rows x 62 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the phrase_data list into a Pandas DataFrame\n",
    "df_phrase = pd.DataFrame(phrase_data)\n",
    "\n",
    "# Print the number of rows and columns of the DataFrame\n",
    "print(f\"Number of Rows: {df_phrase.shape[0]}    Number of Columns: {df_phrase.shape[1]}\\n\")\n",
    "\n",
    "# Display the first 5 rows of the DataFrame to inspect its content\n",
    "df_phrase.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "953fa1a9-d93d-42e7-8713-7f083f024b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'scaledegree', 'scaledegreespecifier', 'tonic', 'mode',\n",
       "       'metriccontour', 'imaweight', 'pitch40', 'midipitch', 'diatonicpitch',\n",
       "       'diatonicinterval', 'chromaticinterval', 'pitchproximity',\n",
       "       'pitchreversal', 'nextisrest', 'restduration_frac', 'duration',\n",
       "       'duration_frac', 'duration_fullname', 'onsettick', 'beatfraction',\n",
       "       'phrasepos', 'phrase_ix', 'phrase_end', 'songpos', 'beatinsong',\n",
       "       'beatinphrase', 'beatinphrase_end', 'IOI_frac', 'IOI', 'IOR',\n",
       "       'imacontour', 'pitch', 'contour3', 'contour5', 'beatstrength',\n",
       "       'beat_str', 'beat_fraction_str', 'beat', 'timesignature',\n",
       "       'gpr2a_Frankland', 'gpr2b_Frankland', 'gpr3a_Frankland',\n",
       "       'gpr3d_Frankland', 'gpr_Frankland_sum', 'lbdm_spitch', 'lbdm_sioi',\n",
       "       'lbdm_srest', 'lbdm_rpitch', 'lbdm_rioi', 'lbdm_rrest',\n",
       "       'lbdm_boundarystrength', 'durationcontour', 'IOR_frac', 'lyrics',\n",
       "       'noncontentword', 'wordend', 'phoneme', 'rhymes', 'rhymescontentwords',\n",
       "       'wordstress', 'melismastate'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_phrase.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e79c344-78f0-4ff9-b6d7-d47692030fac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e71805-bb28-4715-add5-377f9b4f0603",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c21754b3",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "\n",
    "# <span></span>\n",
    "# <span style=\"color: blue; font-size: 30px\">Task 1: Preparation of Data</span>\n",
    "\n",
    "</div>\n",
    "\n",
    "<span style=\"font-size: 16px;\">\n",
    "\n",
    "To predict the `phrase_end` (which indicates whether the tune is the ending of a song), we first need to determine which attributes affect the target attribute most. <strong>Correlation analysis</strong> is the best method for this purpose.\n",
    "\n",
    "However, it accepts only single numerical values. Since the values are stored in arrays for each song, we need to extract each individual tune and store them as a single record by applying the <em>explosion method</em> to the dataset.\n",
    "\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3be20937-77fd-481f-a77e-6cc6cc51ba70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Rows after Explosion: 1296028    Number of Columns after Explosion: 62\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scaledegree</th>\n",
       "      <th>scaledegreespecifier</th>\n",
       "      <th>tonic</th>\n",
       "      <th>mode</th>\n",
       "      <th>metriccontour</th>\n",
       "      <th>imaweight</th>\n",
       "      <th>pitch40</th>\n",
       "      <th>midipitch</th>\n",
       "      <th>diatonicpitch</th>\n",
       "      <th>diatonicinterval</th>\n",
       "      <th>...</th>\n",
       "      <th>IOR_frac</th>\n",
       "      <th>id</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>noncontentword</th>\n",
       "      <th>wordend</th>\n",
       "      <th>phoneme</th>\n",
       "      <th>rhymes</th>\n",
       "      <th>rhymescontentwords</th>\n",
       "      <th>wordstress</th>\n",
       "      <th>melismastate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>P</td>\n",
       "      <td>F</td>\n",
       "      <td>major</td>\n",
       "      <td>None</td>\n",
       "      <td>0.236646</td>\n",
       "      <td>163</td>\n",
       "      <td>72</td>\n",
       "      <td>32</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>NLB125815_01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>A</td>\n",
       "      <td>F</td>\n",
       "      <td>major</td>\n",
       "      <td>-</td>\n",
       "      <td>0.015528</td>\n",
       "      <td>164</td>\n",
       "      <td>73</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1/3</td>\n",
       "      <td>NLB125815_01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>M</td>\n",
       "      <td>F</td>\n",
       "      <td>major</td>\n",
       "      <td>+</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>169</td>\n",
       "      <td>74</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>NLB125815_01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>P</td>\n",
       "      <td>F</td>\n",
       "      <td>major</td>\n",
       "      <td>-</td>\n",
       "      <td>0.204348</td>\n",
       "      <td>163</td>\n",
       "      <td>72</td>\n",
       "      <td>32</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>NLB125815_01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>P</td>\n",
       "      <td>F</td>\n",
       "      <td>major</td>\n",
       "      <td>+</td>\n",
       "      <td>0.392547</td>\n",
       "      <td>157</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>NLB125815_01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  scaledegree scaledegreespecifier tonic   mode metriccontour imaweight  \\\n",
       "0           5                    P     F  major          None  0.236646   \n",
       "0           5                    A     F  major             -  0.015528   \n",
       "0           6                    M     F  major             +  0.913043   \n",
       "0           5                    P     F  major             -  0.204348   \n",
       "0           4                    P     F  major             +  0.392547   \n",
       "\n",
       "  pitch40 midipitch diatonicpitch diatonicinterval  ... IOR_frac  \\\n",
       "0     163        72            32             None  ...     None   \n",
       "0     164        73            32                0  ...      1/3   \n",
       "0     169        74            33                1  ...        4   \n",
       "0     163        72            32               -1  ...        1   \n",
       "0     157        70            31               -1  ...        1   \n",
       "\n",
       "             id lyrics noncontentword wordend phoneme rhymes  \\\n",
       "0  NLB125815_01    NaN            NaN     NaN     NaN    NaN   \n",
       "0  NLB125815_01    NaN            NaN     NaN     NaN    NaN   \n",
       "0  NLB125815_01    NaN            NaN     NaN     NaN    NaN   \n",
       "0  NLB125815_01    NaN            NaN     NaN     NaN    NaN   \n",
       "0  NLB125815_01    NaN            NaN     NaN     NaN    NaN   \n",
       "\n",
       "  rhymescontentwords wordstress melismastate  \n",
       "0                NaN        NaN          NaN  \n",
       "0                NaN        NaN          NaN  \n",
       "0                NaN        NaN          NaN  \n",
       "0                NaN        NaN          NaN  \n",
       "0                NaN        NaN          NaN  \n",
       "\n",
       "[5 rows x 62 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select only the columns with sequence data and preserve other columns as metadata\n",
    "sequence_columns = [col for col in df_phrase.columns if isinstance(df_phrase[col].iloc[0], list)]\n",
    "non_sequence_columns = [col for col in df_phrase.columns if col not in sequence_columns]\n",
    "\n",
    "# Explode the sequence columns into individual rows\n",
    "df_exploded = df_phrase[sequence_columns].apply(pd.Series.explode)\n",
    "\n",
    "# Add the non-sequence metadata columns back into the exploded DataFrame\n",
    "# These columns are repeated to match the number of exploded rows\n",
    "for col in non_sequence_columns:\n",
    "    # Get the length of the sequence in the first sequence column to determine how many times to repeat each metadata value\n",
    "    sequence_length = df_phrase[sequence_columns[0]].str.len()\n",
    "    \n",
    "    # Repeat the values in the non-sequence column to match the number of exploded rows\n",
    "    repeated_values = df_phrase[col].repeat(sequence_length)\n",
    "    \n",
    "    # Reset the index after repetition and assign it to the exploded DataFrame\n",
    "    df_exploded[col] = repeated_values.reset_index(drop=True)\n",
    "\n",
    "\n",
    "print(f\"Number of Rows after Explosion: {df_exploded.shape[0]}    Number of Columns after Explosion: {df_exploded.shape[1]}\\n\")\n",
    "df_exploded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57dea333",
   "metadata": {},
   "source": [
    "#### Now that each individual tune is stored as a separate record, we can proceed to convert their values into numerical format in preparation for correlation analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eebb32a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/82/g6v1v3lj0pl0njbnhxvz04vm0000gn/T/ipykernel_36177/2796930850.py:8: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df_exploded[col] = pd.to_numeric(df_exploded[col], errors = \"ignore\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Rows: 1296028    Number of Columns: 41\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scaledegree</th>\n",
       "      <th>imaweight</th>\n",
       "      <th>pitch40</th>\n",
       "      <th>midipitch</th>\n",
       "      <th>diatonicpitch</th>\n",
       "      <th>diatonicinterval</th>\n",
       "      <th>chromaticinterval</th>\n",
       "      <th>pitchproximity</th>\n",
       "      <th>pitchreversal</th>\n",
       "      <th>nextisrest</th>\n",
       "      <th>...</th>\n",
       "      <th>lbdm_rrest</th>\n",
       "      <th>lbdm_boundarystrength</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>noncontentword</th>\n",
       "      <th>wordend</th>\n",
       "      <th>phoneme</th>\n",
       "      <th>rhymes</th>\n",
       "      <th>rhymescontentwords</th>\n",
       "      <th>wordstress</th>\n",
       "      <th>melismastate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0.236646</td>\n",
       "      <td>163</td>\n",
       "      <td>72</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0.015528</td>\n",
       "      <td>164</td>\n",
       "      <td>73</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.026523</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>169</td>\n",
       "      <td>74</td>\n",
       "      <td>33</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.057262</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0.204348</td>\n",
       "      <td>163</td>\n",
       "      <td>72</td>\n",
       "      <td>32</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0.392547</td>\n",
       "      <td>157</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010476</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   scaledegree  imaweight  pitch40  midipitch  diatonicpitch  \\\n",
       "0            5   0.236646      163         72             32   \n",
       "0            5   0.015528      164         73             32   \n",
       "0            6   0.913043      169         74             33   \n",
       "0            5   0.204348      163         72             32   \n",
       "0            4   0.392547      157         70             31   \n",
       "\n",
       "   diatonicinterval  chromaticinterval  pitchproximity  pitchreversal  \\\n",
       "0               NaN                NaN             NaN            NaN   \n",
       "0               0.0                1.0             NaN            NaN   \n",
       "0               1.0                1.0             1.0            0.0   \n",
       "0              -1.0               -2.0             2.0            1.5   \n",
       "0              -1.0               -2.0             2.0            0.0   \n",
       "\n",
       "   nextisrest  ...  lbdm_rrest  lbdm_boundarystrength  lyrics  noncontentword  \\\n",
       "0         0.0  ...         NaN                    NaN     NaN             NaN   \n",
       "0         0.0  ...         0.0               0.026523     NaN             NaN   \n",
       "0         0.0  ...         0.0               0.057262     NaN             NaN   \n",
       "0         0.0  ...         0.0               0.006667     NaN             NaN   \n",
       "0         0.0  ...         0.0               0.010476     NaN             NaN   \n",
       "\n",
       "   wordend  phoneme  rhymes  rhymescontentwords  wordstress  melismastate  \n",
       "0      NaN      NaN     NaN                 NaN         NaN           NaN  \n",
       "0      NaN      NaN     NaN                 NaN         NaN           NaN  \n",
       "0      NaN      NaN     NaN                 NaN         NaN           NaN  \n",
       "0      NaN      NaN     NaN                 NaN         NaN           NaN  \n",
       "0      NaN      NaN     NaN                 NaN         NaN           NaN  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converts phrase_end values to numeric ones (True -> 1, False -> 0)\n",
    "df_exploded[\"phrase_end\"] = df_exploded[\"phrase_end\"].astype(int)\n",
    "\n",
    "# Convert all columns to numeric, excluding the 'id' column\n",
    "# The 'errors=\"ignore\"' ensures that non-numeric columns remain unchanged\n",
    "for col in df_exploded.columns:\n",
    "    if col != \"id\":\n",
    "        df_exploded[col] = pd.to_numeric(df_exploded[col], errors = \"ignore\")\n",
    "\n",
    "# Drops the 'id' column and chooses only the columns that were successfully converted to numeric\n",
    "df_numeric = df_exploded.drop(columns = [\"id\"]).select_dtypes(include = [\"number\"])\n",
    "\n",
    "print(f\"Number of Rows: {df_numeric.shape[0]}    Number of Columns: {df_numeric.shape[1]}\\n\")\n",
    "df_numeric.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb843c3",
   "metadata": {},
   "source": [
    "#### `df_numeric` is the dataset that contains attributes whose values were successfully converted to numeric ones. Now we can perform the **correlation analysis.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "202c630e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation with 'phrase_end':\n",
      "phrase_end               1.000000\n",
      "lbdm_boundarystrength    0.491565\n",
      "phrasepos                0.481625\n",
      "lbdm_sioi                0.430348\n",
      "IOI                      0.399007\n",
      "duration                 0.397352\n",
      "IOR                      0.386167\n",
      "nextisrest               0.384382\n",
      "lbdm_srest               0.347842\n",
      "gpr2b_Frankland          0.291809\n",
      "gpr_Frankland_sum        0.255393\n",
      "lbdm_rrest               0.225675\n",
      "lbdm_spitch              0.223347\n",
      "lbdm_rioi                0.216156\n",
      "imaweight                0.186840\n",
      "beatstrength             0.170354\n",
      "gpr2a_Frankland          0.168731\n",
      "lbdm_rpitch              0.119988\n",
      "gpr3d_Frankland          0.118248\n",
      "songpos                  0.070903\n",
      "gpr3a_Frankland          0.057045\n",
      "phrase_ix                0.014938\n",
      "beat_str                -0.002449\n",
      "pitchreversal           -0.010129\n",
      "onsettick               -0.011849\n",
      "pitchproximity          -0.019382\n",
      "beat                    -0.063904\n",
      "diatonicinterval        -0.090256\n",
      "scaledegree             -0.090477\n",
      "chromaticinterval       -0.100981\n",
      "diatonicpitch           -0.107615\n",
      "pitch40                 -0.122948\n",
      "midipitch               -0.124859\n",
      "lyrics                        NaN\n",
      "noncontentword                NaN\n",
      "wordend                       NaN\n",
      "phoneme                       NaN\n",
      "rhymes                        NaN\n",
      "rhymescontentwords            NaN\n",
      "wordstress                    NaN\n",
      "melismastate                  NaN\n",
      "Name: phrase_end, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Calculate the correlation matrix for the numeric data\n",
    "correlation_matrix = df_numeric.corr()\n",
    "\n",
    "# Extract and sort the correlation with the target variable 'phrase_end'\n",
    "correlation_with_target = correlation_matrix[\"phrase_end\"].sort_values(ascending = False)\n",
    "print(f\"Correlation with 'phrase_end':\\n{correlation_with_target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ddb7e221-302a-45d6-97ae-1ea1fa7d2d40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Drop 'phrase_end' from the correlation data and select the top 10 features with highest correlation\n",
    "top_correlations = correlation_with_target.drop(\"phrase_end\").head(10)\n",
    "\n",
    "# Plot the top 10 correlations as a bar chart\n",
    "top_correlations.plot(kind=\"bar\", figsize=(12, 6))\n",
    "plt.title(\"Top 10 Correlated Features with 'phrase_end'\")\n",
    "plt.ylabel(\"Correlation Coefficient\")\n",
    "plt.xlabel(\"Features\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7c1280",
   "metadata": {},
   "source": [
    "#### From the bar chart, we can see the top 10 attributes that are correlated more with the target attribute than others. We will apply a threshold to choose only the best attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df3806d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features:\n",
      "['lbdm_boundarystrength', 'phrasepos', 'lbdm_sioi', 'IOI', 'duration', 'IOR', 'nextisrest', 'lbdm_srest', 'gpr2b_Frankland', 'gpr_Frankland_sum', 'lbdm_rrest', 'lbdm_spitch', 'lbdm_rioi']\n",
      "Number of Features: 13\n"
     ]
    }
   ],
   "source": [
    "# Select features with absolute correlation greater than threshold value with the target variable\n",
    "selected_features = correlation_with_target[correlation_with_target.abs() > 0.2].index.tolist()\n",
    "\n",
    "# Exclude 'phrase_end' from the selected features as it is the target variable\n",
    "selected_features = [feature for feature in selected_features if feature != 'phrase_end']\n",
    "\n",
    "print(f\"Selected Features:\\n{selected_features}\")\n",
    "print(f\"Number of Features: {len(selected_features)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5653fe6-930b-4e0e-9981-252d4ffab1c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d9fb3f-4976-4785-b6e2-a671426e9387",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d8bc094f",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "\n",
    "# <span></span>\n",
    "# <span style=\"color: blue; font-size: 30px\">Task 2: Learning</span>\n",
    "\n",
    "</div>\n",
    "\n",
    "<span style=\"font-size: 16px;\">\n",
    "\n",
    "Before training the models on the dataset, we have to make sure that the dataset is fully prepared for training. Unfortunately, there is one problem: **NaN** values are scattered everywhere in the dataset. Some attributes have many, while others contain a small portion of them. We decided to implement different strategies to solve this problem:\n",
    "\n",
    "1. **Columns with more than 90% NaN values**: These attributes will not significantly affect the predictions since the majority of the values are NaN. Therefore, we can confidently remove these columns.\n",
    "2. **Columns with a moderate number of NaN values**: We can use *imputation*, which fills NaN values with certain values obtained using a strategy such as *mean, median,* or *mode*. We chose to use **mean imputation**, meaning that for a single column, the average of its values will be computed, and then all NaN values will be replaced by this value. This helps to keep the relationship between values.\n",
    "3. **Columns with relatively few NaN values**: Since these columns are critical for predictions, the best method is to *remove the records* where these columns have NaN values.\n",
    "\n",
    "</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d7e7bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scaledegree                    0\n",
      "imaweight                      0\n",
      "pitch40                        0\n",
      "midipitch                      0\n",
      "diatonicpitch                  0\n",
      "diatonicinterval           18108\n",
      "chromaticinterval          18108\n",
      "pitchproximity             52596\n",
      "pitchreversal              56809\n",
      "nextisrest                 14470\n",
      "duration                       0\n",
      "onsettick                      0\n",
      "phrasepos                      0\n",
      "phrase_ix                      0\n",
      "phrase_end                     0\n",
      "songpos                        0\n",
      "IOI                        14470\n",
      "IOR                        32578\n",
      "beatstrength               43556\n",
      "beat_str                   43556\n",
      "beat                       43556\n",
      "gpr2a_Frankland          1271573\n",
      "gpr2b_Frankland          1111054\n",
      "gpr3a_Frankland          1065652\n",
      "gpr3d_Frankland           889668\n",
      "gpr_Frankland_sum              0\n",
      "lbdm_spitch                54324\n",
      "lbdm_sioi                  54324\n",
      "lbdm_srest                 54324\n",
      "lbdm_rpitch                36216\n",
      "lbdm_rioi                  36216\n",
      "lbdm_rrest                 36216\n",
      "lbdm_boundarystrength      54324\n",
      "lyrics                   1296028\n",
      "noncontentword           1296028\n",
      "wordend                  1296028\n",
      "phoneme                  1296028\n",
      "rhymes                   1296028\n",
      "rhymescontentwords       1296028\n",
      "wordstress               1296028\n",
      "melismastate             1296028\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# To determine the number of NaN values for each column\n",
    "print(df_numeric.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f836ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of total NaN values:  0\n"
     ]
    }
   ],
   "source": [
    "# 1. Dropping columns with majority of values being NaN \n",
    "threshold = 0.9 * len(df_numeric)\n",
    "df_numeric = df_numeric.loc[:, df_numeric.isna().sum() < threshold]\n",
    "\n",
    "# 2. Removing rows where critical columns have NaN values\n",
    "critical_columns = [\"nextisrest\", \"diatonicinterval\", \"chromaticinterval\", \"IOI\"]\n",
    "df_numeric = df_numeric.dropna(subset = critical_columns)\n",
    "\n",
    "# 3. Mean imputation for columns with moderate number of NaN values\n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(strategy = \"mean\")\n",
    "df_numeric.iloc[:, :] = imputer.fit_transform(df_numeric)\n",
    "\n",
    "# Verifying that there are no remaining NaN values\n",
    "print(\"Number of total NaN values: \", df_numeric.isna().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c4b64b",
   "metadata": {},
   "source": [
    "##### The data is ready. Now we can split the data into training and test sets, and train models for making predictions.\n",
    "We chose 4 models to predict the target variable: \n",
    "* Logistic Regression\n",
    "* Decision Tree\n",
    "* Random Forest\n",
    "* Neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aaa07849",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Splitting the dataset\n",
    "X = df_numeric.drop(columns = ['phrase_end']) # Features\n",
    "X = X[selected_features] # Choosing only important attributes\n",
    "y = df_numeric['phrase_end'] # Target\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7732f507",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "95f2b039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 1.00\n",
      "CPU times: user 2.44 s, sys: 106 ms, total: 2.55 s\n",
      "Wall time: 1.29 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Initialize the Logistic Regression model with specified parameters:\n",
    "# - max_iter: Maximum number of iterations for the solver (set to 1000 for convergence).\n",
    "# - class_weight: Adjusts weights for classes to handle imbalanced datasets ('balanced' computes weights automatically).\n",
    "# - random_state: Ensures reproducibility by fixing the random seed.\n",
    "log_reg = LogisticRegression(max_iter=1000, class_weight=\"balanced\", random_state=42)\n",
    "\n",
    "# Fit the Logistic Regression model using the training data (features and labels)\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Predict the target values for the test set\n",
    "log_reg_pred = log_reg.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model on the test set\n",
    "log_reg_acc = accuracy_score(y_test, log_reg_pred)\n",
    "\n",
    "# Print the accuracy of the Logistic Regression model\n",
    "print(f\"Logistic Regression Accuracy: {log_reg_acc:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9759b49d",
   "metadata": {},
   "source": [
    "#### The accuracy of the Logistic Regression is 1.00 (100%), which means that the model is likely *overfitting*. Even though we know that the correlation coefficients of the selected attributes are moderate to low, there could still be a high reliance on a single attribute to predict the target. To verify this, we can look at Logistic Regression coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "218a4c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phrasepos                96.625284\n",
      "gpr2b_Frankland          12.868939\n",
      "lbdm_srest                8.753301\n",
      "nextisrest                5.533051\n",
      "IOI                       4.288747\n",
      "lbdm_rrest                4.177195\n",
      "duration                  1.741313\n",
      "lbdm_boundarystrength     1.531766\n",
      "lbdm_spitch               1.320539\n",
      "gpr_Frankland_sum         1.081885\n",
      "lbdm_sioi                 0.652848\n",
      "IOR                       0.501464\n",
      "lbdm_rioi                 0.272318\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Import NumPy for numerical operations\n",
    "import numpy as np\n",
    "\n",
    "# Extract the importance of each feature from the model's coefficients\n",
    "# The Logistic Regression model's coefficients (log_reg.coef_) indicate the influence of each feature on the target.\n",
    "# Taking the absolute values of the coefficients makes it easier to compare their importance.\n",
    "importance = np.abs(log_reg.coef_[0])\n",
    "\n",
    "# Create a Pandas Series to map each feature to its importance score\n",
    "# - The index of the series is set to the feature names (X_train.columns).\n",
    "# - The values are sorted in descending order to list the most important features first.\n",
    "feature_importance = pd.Series(importance, index=X_train.columns).sort_values(ascending=False)\n",
    "\n",
    "# Print the feature importance scores\n",
    "print(feature_importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8de65b",
   "metadata": {},
   "source": [
    "We can see that the `phrasepos` attribute has a very high coefficient compared to others. This means that the model heavily relies on it to make predictions, not accounting for the input from other features. So, the model is not generalizing but rather making predictions based on the `phrasepos` attribute. So, we will remove it from the dataset and train the model again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c8b41a7c-1da2-4641-b09b-f39c0f914f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.84\n"
     ]
    }
   ],
   "source": [
    "# Dataset without 'phrasepos' column\n",
    "X_train_reduced = X_train.drop(columns = [\"phrasepos\"])\n",
    "X_test_reduced = X_test.drop(columns = [\"phrasepos\"])\n",
    "\n",
    "# Train the Logistic Regression model again using the reduced feature set\n",
    "log_reg.fit(X_train_reduced, y_train)\n",
    "\n",
    "# Use the trained model to make predictions on the test set (reduced feature set)\n",
    "log_reg_pred = log_reg.predict(X_test_reduced)\n",
    "\n",
    "# Display the accuracy of the model after removing the 'phrasepos' feature\n",
    "log_reg_acc = accuracy_score(y_test, log_reg_pred)\n",
    "\n",
    "# Display new model's accuracy\n",
    "print(f\"Logistic Regression Accuracy: {log_reg_acc:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df90b31",
   "metadata": {},
   "source": [
    "The accuracy of the model dropped. This shows that there is no overfitting and the model is doing a great job in generalization. Let's make sure that feature importance coefficients are evenly distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fa170517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.838850\n",
      "Test Accuracy: 0.839851\n",
      "Cross-Validation Accuracy: 0.839146\n",
      "\n",
      "Feature importance:\n",
      "nextisrest               5.419989\n",
      "lbdm_rrest               2.789008\n",
      "gpr2b_Frankland          2.154717\n",
      "lbdm_spitch              1.485973\n",
      "lbdm_sioi                1.238513\n",
      "lbdm_boundarystrength    1.028863\n",
      "duration                 1.021846\n",
      "gpr_Frankland_sum        0.704102\n",
      "lbdm_rioi                0.199816\n",
      "lbdm_srest               0.152452\n",
      "IOR                      0.140650\n",
      "IOI                      0.112607\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Comparing the training and test accuracy\n",
    "train_acc = accuracy_score(y_train, log_reg.predict(X_train_reduced))\n",
    "print(f\"Training Accuracy: {train_acc:.6f}\")\n",
    "print(f\"Test Accuracy: {log_reg_acc:.6f}\")\n",
    "\n",
    "# Performing cross-validation\n",
    "cv_scores = cross_val_score(log_reg, X_train_reduced, y_train, cv = 5, scoring = \"accuracy\")\n",
    "print(f\"Cross-Validation Accuracy: {cv_scores.mean():.6f}\")\n",
    "\n",
    "# Checking the distribution of the importance on features\n",
    "importance = np.abs(log_reg.coef_[0])\n",
    "feature_importance = pd.Series(importance, index = X_train_reduced.columns).sort_values(ascending = False)\n",
    "print(\"\\nFeature importance:\")\n",
    "print(feature_importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d224702e",
   "metadata": {},
   "source": [
    "##### This table confirms that the importance is evenly distributed among the features. So, it is a great result.\n",
    "##### To verify the legitimacy of the score, we use three strategies: \n",
    "1. Comparing the training and test accuracy. \n",
    "2. Performing a cross-validation.\n",
    "3. Checking the feature importance (if it is evenly distributed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd9554c",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b3a34bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 0.94\n",
      "CPU times: user 3 s, sys: 19.4 ms, total: 3.02 s\n",
      "Wall time: 3.03 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Initialize a Decision Tree classifier with a maximum depth of 20 to prevent overfitting\n",
    "# random_state ensures reproducibility of results\n",
    "decision_tree = DecisionTreeClassifier(max_depth=20, random_state=42)\n",
    "\n",
    "# Train the Decision Tree classifier on the reduced training dataset\n",
    "decision_tree.fit(X_train_reduced, y_train)\n",
    "\n",
    "# Make predictions on the reduced test dataset using the trained model\n",
    "decision_tree_pred = decision_tree.predict(X_test_reduced)\n",
    "\n",
    "# Evaluate the accuracy of the model by comparing predictions to true labels\n",
    "decision_tree_acc = accuracy_score(y_test, decision_tree_pred)\n",
    "\n",
    "# Print the accuracy score of the Decision Tree model\n",
    "print(f\"Decision Tree Accuracy: {decision_tree_acc:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58776dd9",
   "metadata": {},
   "source": [
    "##### Verifying the score of the Decision Tree using the same strategies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e32037e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.958092\n",
      "Test Accuracy: 0.943413\n",
      "Decision Tree Depth: 20\n",
      "Cross-Validation Accuracy: 0.942499\n",
      "\n",
      "Feature importance:\n",
      "lbdm_boundarystrength    0.552446\n",
      "lbdm_spitch              0.090974\n",
      "nextisrest               0.084396\n",
      "gpr_Frankland_sum        0.075469\n",
      "lbdm_sioi                0.052396\n",
      "IOI                      0.042290\n",
      "lbdm_rioi                0.023232\n",
      "duration                 0.021646\n",
      "IOR                      0.019596\n",
      "gpr2b_Frankland          0.016754\n",
      "lbdm_srest               0.011385\n",
      "lbdm_rrest               0.009416\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Comparing the training and test accuracy\n",
    "train_acc = accuracy_score(y_train, decision_tree.predict(X_train_reduced))\n",
    "print(f\"Training Accuracy: {train_acc:.6f}\")\n",
    "print(f\"Test Accuracy: {decision_tree_acc:.6f}\")\n",
    "print(f\"Decision Tree Depth: {decision_tree.get_depth()}\") # Checking the depth to make sure that the tree is not too deep\n",
    "\n",
    "# Performing cross-validation\n",
    "cv_scores = cross_val_score(decision_tree, X_train_reduced, y_train, cv = 5, scoring = \"accuracy\")\n",
    "print(f\"Cross-Validation Accuracy: {cv_scores.mean():.6f}\")\n",
    "\n",
    "# Checking the distribution of the importance on features\n",
    "feature_importances = pd.Series(decision_tree.feature_importances_, index=X_train_reduced.columns).sort_values(ascending = False)\n",
    "print(\"\\nFeature importance:\")\n",
    "print(feature_importances)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c0d945",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1bfaf6ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.944968\n",
      "CPU times: user 13.4 s, sys: 85.6 ms, total: 13.5 s\n",
      "Wall time: 13.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize a Random Forest Classifier with 15 decision trees\n",
    "# - n_estimators: Specifies the number of trees in the forest (15 for faster computation)\n",
    "# - random_state: Ensures reproducibility of the results\n",
    "random_forest = RandomForestClassifier(n_estimators=15, random_state=42)\n",
    "\n",
    "# Train the Random Forest Classifier using the reduced training dataset\n",
    "# - X_train_reduced: Features after removing less important ones\n",
    "# - y_train: Target variable\n",
    "random_forest.fit(X_train_reduced, y_train)\n",
    "\n",
    "# Make predictions on the reduced test dataset\n",
    "# - X_test_reduced: Test features (reduced version, same as training)\n",
    "random_forest_pred = random_forest.predict(X_test_reduced)\n",
    "\n",
    "# Calculate the accuracy of the Random Forest model\n",
    "# - accuracy_score: Compares predicted values with actual test labels\n",
    "random_forest_acc = accuracy_score(y_test, random_forest_pred)\n",
    "\n",
    "# Print the accuracy score of the Random Forest model\n",
    "print(f\"Random Forest Accuracy: {random_forest_acc:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc69b2c",
   "metadata": {},
   "source": [
    "##### Verifying the score of the Random Forest using the same strategies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "461208db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.973047\n",
      "Test Accuracy: 0.944968\n",
      "Cross-Validation Accuracy: 0.942941\n",
      "\n",
      "Feature importance:\n",
      "lbdm_boundarystrength    0.301501\n",
      "lbdm_spitch              0.178498\n",
      "lbdm_sioi                0.125467\n",
      "gpr_Frankland_sum        0.097465\n",
      "nextisrest               0.077920\n",
      "IOI                      0.061059\n",
      "IOR                      0.041708\n",
      "duration                 0.033939\n",
      "lbdm_srest               0.026841\n",
      "gpr2b_Frankland          0.024835\n",
      "lbdm_rioi                0.016488\n",
      "lbdm_rrest               0.014279\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Comparing the training and test accuracy\n",
    "train_acc = accuracy_score(y_train, random_forest.predict(X_train_reduced))\n",
    "print(f\"Training Accuracy: {train_acc:.6f}\")\n",
    "print(f\"Test Accuracy: {random_forest_acc:.6f}\")\n",
    "\n",
    "# Performing cross-validation with cv = 3\n",
    "cv_scores = cross_val_score(random_forest, X_train_reduced, y_train, cv = 3, scoring = \"accuracy\")\n",
    "print(f\"Cross-Validation Accuracy: {cv_scores.mean():.6f}\")\n",
    "\n",
    "# Checking the distribution of the importance on features\n",
    "feature_importances = pd.Series(random_forest.feature_importances_, index=X_train_reduced.columns).sort_values(ascending = False)\n",
    "print(\"\\nFeature importance:\")\n",
    "print(feature_importances)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d97801",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "95d95197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Accuracy: 0.943706\n",
      "CPU times: user 16.2 s, sys: 526 ms, total: 16.7 s\n",
      "Wall time: 15 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Initialize the Multi-Layer Perceptron (MLP) classifier\n",
    "# - hidden_layer_sizes=(50,): Defines one hidden layer with 50 neurons\n",
    "# - max_iter=500: Sets the maximum number of iterations for training\n",
    "# - early_stopping=True: Stops training early if validation score doesn't improve\n",
    "# - random_state=42: Ensures reproducibility\n",
    "neural_net = MLPClassifier(hidden_layer_sizes=(50,), max_iter=500, early_stopping=True, random_state=42)\n",
    "\n",
    "# Train the neural network on the reduced training data\n",
    "neural_net.fit(X_train_reduced, y_train)\n",
    "\n",
    "# Predict the target values for the reduced test data\n",
    "neural_net_pred = neural_net.predict(X_test_reduced)\n",
    "\n",
    "# Calculate the accuracy score for the predictions\n",
    "neural_net_acc = accuracy_score(y_test, neural_net_pred)\n",
    "\n",
    "# Print the neural network accuracy\n",
    "print(f\"Neural Network Accuracy: {neural_net_acc:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d275292",
   "metadata": {},
   "source": [
    "##### Verifying the score of the Neural Network by using the same strategies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a85ba609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.943587\n",
      "Test Accuracy: 0.943706\n",
      "\n",
      "Feature Importance:\n",
      "nextisrest               0.015484\n",
      "IOR                      0.010393\n",
      "gpr_Frankland_sum        0.006257\n",
      "lbdm_boundarystrength    0.005001\n",
      "lbdm_sioi                0.004804\n",
      "IOI                      0.004590\n",
      "duration                 0.003933\n",
      "lbdm_rioi                0.001320\n",
      "lbdm_rrest               0.001192\n",
      "lbdm_spitch              0.000452\n",
      "lbdm_srest               0.000247\n",
      "gpr2b_Frankland          0.000078\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Comparing the training and test accuracy\n",
    "train_acc = accuracy_score(y_train, neural_net.predict(X_train_reduced))\n",
    "print(f\"Training Accuracy: {train_acc:.6f}\")\n",
    "print(f\"Test Accuracy: {neural_net_acc:.6f}\")\n",
    "\n",
    "# No Cross-validation since it takes too much time\n",
    "\n",
    "# Checking feature importance\n",
    "result = permutation_importance(neural_net, X_test_reduced, y_test, n_repeats = 10, random_state = 42)\n",
    "feature_importances = pd.Series(result.importances_mean, index = X_test_reduced.columns).sort_values(ascending = False)\n",
    "print(\"\\nFeature Importance:\")\n",
    "print(feature_importances)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e037909",
   "metadata": {},
   "source": [
    "### Accuracy scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4dbbc3db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Scores\n",
      "\n",
      "Logistic Regression: 0.839851\n",
      "Decision Tree: 0.943413\n",
      "Random Forest: 0.944968\n",
      "Neural Network: 0.943706\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy Scores\\n\")\n",
    "print(f\"Logistic Regression: {log_reg_acc:.6f}\")\n",
    "print(f\"Decision Tree: {decision_tree_acc:.6f}\")\n",
    "print(f\"Random Forest: {random_forest_acc:.6f}\")\n",
    "print(f\"Neural Network: {neural_net_acc:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "24be9ba0-cb6c-4fbb-988f-4ef53a1245cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_model(model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7e430895-1be8-44c7-af2c-06e7b0d17f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sizes = [0.2, 0.25, 0.3]\n",
    "correlation_thresholds = [0.15, 0.2, 0.25, 0.3]\n",
    "models = [log_reg, decision_tree, random_forest, neural_net]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cc796a09-2eed-44f2-8ac8-a513ff4fffa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation Threshold: 0.15   Test Size: 0.20   Accuracy: 0.838577    Model: LogisticRegression\n",
      "Correlation Threshold: 0.15   Test Size: 0.20   Accuracy: 0.940116    Model: DecisionTreeClassifier\n",
      "Correlation Threshold: 0.15   Test Size: 0.20   Accuracy: 0.941232    Model: RandomForestClassifier\n",
      "Correlation Threshold: 0.15   Test Size: 0.20   Accuracy: 0.943955    Model: MLPClassifier\n",
      "Correlation Threshold: 0.15   Test Size: 0.25   Accuracy: 0.838101    Model: LogisticRegression\n",
      "Correlation Threshold: 0.15   Test Size: 0.25   Accuracy: 0.940018    Model: DecisionTreeClassifier\n",
      "Correlation Threshold: 0.15   Test Size: 0.25   Accuracy: 0.941259    Model: RandomForestClassifier\n",
      "Correlation Threshold: 0.15   Test Size: 0.25   Accuracy: 0.944011    Model: MLPClassifier\n",
      "Correlation Threshold: 0.15   Test Size: 0.30   Accuracy: 0.838015    Model: LogisticRegression\n",
      "Correlation Threshold: 0.15   Test Size: 0.30   Accuracy: 0.939264    Model: DecisionTreeClassifier\n",
      "Correlation Threshold: 0.15   Test Size: 0.30   Accuracy: 0.940684    Model: RandomForestClassifier\n",
      "Correlation Threshold: 0.15   Test Size: 0.30   Accuracy: 0.944166    Model: MLPClassifier\n",
      "Correlation Threshold: 0.20   Test Size: 0.20   Accuracy: 0.844323    Model: LogisticRegression\n",
      "Correlation Threshold: 0.20   Test Size: 0.20   Accuracy: 0.943817    Model: DecisionTreeClassifier\n",
      "Correlation Threshold: 0.20   Test Size: 0.20   Accuracy: 0.945020    Model: RandomForestClassifier\n",
      "Correlation Threshold: 0.20   Test Size: 0.20   Accuracy: 0.943765    Model: MLPClassifier\n",
      "Correlation Threshold: 0.20   Test Size: 0.25   Accuracy: 0.843711    Model: LogisticRegression\n",
      "Correlation Threshold: 0.20   Test Size: 0.25   Accuracy: 0.943143    Model: DecisionTreeClassifier\n",
      "Correlation Threshold: 0.20   Test Size: 0.25   Accuracy: 0.944413    Model: RandomForestClassifier\n",
      "Correlation Threshold: 0.20   Test Size: 0.25   Accuracy: 0.943884    Model: MLPClassifier\n",
      "Correlation Threshold: 0.20   Test Size: 0.30   Accuracy: 0.843598    Model: LogisticRegression\n",
      "Correlation Threshold: 0.20   Test Size: 0.30   Accuracy: 0.942908    Model: DecisionTreeClassifier\n",
      "Correlation Threshold: 0.20   Test Size: 0.30   Accuracy: 0.944380    Model: RandomForestClassifier\n",
      "Correlation Threshold: 0.20   Test Size: 0.30   Accuracy: 0.943667    Model: MLPClassifier\n",
      "Correlation Threshold: 0.25   Test Size: 0.20   Accuracy: 0.844794    Model: LogisticRegression\n",
      "Correlation Threshold: 0.25   Test Size: 0.20   Accuracy: 0.943286    Model: DecisionTreeClassifier\n",
      "Correlation Threshold: 0.25   Test Size: 0.20   Accuracy: 0.944010    Model: RandomForestClassifier\n",
      "Correlation Threshold: 0.25   Test Size: 0.20   Accuracy: 0.943346    Model: MLPClassifier\n",
      "Correlation Threshold: 0.25   Test Size: 0.25   Accuracy: 0.844341    Model: LogisticRegression\n",
      "Correlation Threshold: 0.25   Test Size: 0.25   Accuracy: 0.943162    Model: DecisionTreeClassifier\n",
      "Correlation Threshold: 0.25   Test Size: 0.25   Accuracy: 0.943833    Model: RandomForestClassifier\n",
      "Correlation Threshold: 0.25   Test Size: 0.25   Accuracy: 0.943194    Model: MLPClassifier\n",
      "Correlation Threshold: 0.25   Test Size: 0.30   Accuracy: 0.844294    Model: LogisticRegression\n",
      "Correlation Threshold: 0.25   Test Size: 0.30   Accuracy: 0.942847    Model: DecisionTreeClassifier\n",
      "Correlation Threshold: 0.25   Test Size: 0.30   Accuracy: 0.943269    Model: RandomForestClassifier\n",
      "Correlation Threshold: 0.25   Test Size: 0.30   Accuracy: 0.943404    Model: MLPClassifier\n",
      "Correlation Threshold: 0.30   Test Size: 0.20   Accuracy: 0.848467    Model: LogisticRegression\n",
      "Correlation Threshold: 0.30   Test Size: 0.20   Accuracy: 0.942978    Model: DecisionTreeClassifier\n",
      "Correlation Threshold: 0.30   Test Size: 0.20   Accuracy: 0.942277    Model: RandomForestClassifier\n",
      "Correlation Threshold: 0.30   Test Size: 0.20   Accuracy: 0.942985    Model: MLPClassifier\n",
      "Correlation Threshold: 0.30   Test Size: 0.25   Accuracy: 0.848077    Model: LogisticRegression\n",
      "Correlation Threshold: 0.30   Test Size: 0.25   Accuracy: 0.942997    Model: DecisionTreeClassifier\n",
      "Correlation Threshold: 0.30   Test Size: 0.25   Accuracy: 0.941953    Model: RandomForestClassifier\n",
      "Correlation Threshold: 0.30   Test Size: 0.25   Accuracy: 0.942538    Model: MLPClassifier\n",
      "Correlation Threshold: 0.30   Test Size: 0.30   Accuracy: 0.847982    Model: LogisticRegression\n",
      "Correlation Threshold: 0.30   Test Size: 0.30   Accuracy: 0.942512    Model: DecisionTreeClassifier\n",
      "Correlation Threshold: 0.30   Test Size: 0.30   Accuracy: 0.941570    Model: RandomForestClassifier\n",
      "Correlation Threshold: 0.30   Test Size: 0.30   Accuracy: 0.942652    Model: MLPClassifier\n",
      "CPU times: user 7min 54s, sys: 10.9 s, total: 8min 5s\n",
      "Wall time: 7min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "results = []\n",
    "\n",
    "for correlation_threshold in correlation_thresholds:\n",
    "    X = df_numeric.drop(columns = ['phrase_end']) # Features\n",
    "    y = df_numeric['phrase_end'] # Target\n",
    "\n",
    "    # Calculate the correlation matrix for the numeric data\n",
    "    correlation_matrix = df_numeric.corr()\n",
    "    \n",
    "    # Extract and sort the correlation with the target variable 'phrase_end'\n",
    "    correlation_with_target = correlation_matrix[\"phrase_end\"].sort_values(ascending = False)\n",
    "    \n",
    "    # Select features with correlation above the threshold\n",
    "    selected_features = correlation_with_target[correlation_with_target.abs() > correlation_threshold].index.tolist()\n",
    "    selected_features.remove('phrase_end')\n",
    "\n",
    "    # Reduce the dataset\n",
    "    X_reduced = X[selected_features]\n",
    "\n",
    "    for test_size in test_sizes:\n",
    "        # Train-test split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_reduced, y, test_size=test_size, random_state=42)\n",
    "\n",
    "        X_train_reduced = X_train.drop(columns = [\"phrasepos\"])\n",
    "        X_test_reduced = X_test.drop(columns = [\"phrasepos\"])\n",
    "\n",
    "        for model in models:\n",
    "            # Train and evaluate\n",
    "            accuracy = train_and_evaluate_model(model, X_train_reduced, X_test_reduced, y_train, y_test)\n",
    "\n",
    "            # Append results to the list\n",
    "            results.append({\n",
    "                \"Model\": model.__class__.__name__,\n",
    "                \"Test Size\": test_size,\n",
    "                \"Correlation Threshold\": correlation_threshold,\n",
    "                \"Accuracy\": accuracy\n",
    "            })\n",
    "\n",
    "            print(f\"Correlation Threshold: {correlation_threshold:.2f}   Test Size: {test_size:.2f}   Accuracy: {accuracy:.6f}    Model: {model.__class__.__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812c2cd3-7e5e-4672-92e2-8577fbd3eea6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6cc3e6ab-c30a-4898-9cbe-26777877c4cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Test Size</th>\n",
       "      <th>Correlation Threshold</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.838577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.940116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.941232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.943955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.838101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.940018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.941259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.944011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.838015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.939264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.940684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.944166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.844323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.943817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.945020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.943765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.843711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.943143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.944413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.943884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.843598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.942908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.944380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.943667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.844794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.943286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.944010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.943346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.844341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.943162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.943833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.943194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.844294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.942847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.943269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.943404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.848467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.942978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.942277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.942985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.848077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.942997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.941953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.942538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.847982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.942512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.941570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.942652</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Model  Test Size  Correlation Threshold  Accuracy\n",
       "0       LogisticRegression       0.20                   0.15  0.838577\n",
       "1   DecisionTreeClassifier       0.20                   0.15  0.940116\n",
       "2   RandomForestClassifier       0.20                   0.15  0.941232\n",
       "3            MLPClassifier       0.20                   0.15  0.943955\n",
       "4       LogisticRegression       0.25                   0.15  0.838101\n",
       "5   DecisionTreeClassifier       0.25                   0.15  0.940018\n",
       "6   RandomForestClassifier       0.25                   0.15  0.941259\n",
       "7            MLPClassifier       0.25                   0.15  0.944011\n",
       "8       LogisticRegression       0.30                   0.15  0.838015\n",
       "9   DecisionTreeClassifier       0.30                   0.15  0.939264\n",
       "10  RandomForestClassifier       0.30                   0.15  0.940684\n",
       "11           MLPClassifier       0.30                   0.15  0.944166\n",
       "12      LogisticRegression       0.20                   0.20  0.844323\n",
       "13  DecisionTreeClassifier       0.20                   0.20  0.943817\n",
       "14  RandomForestClassifier       0.20                   0.20  0.945020\n",
       "15           MLPClassifier       0.20                   0.20  0.943765\n",
       "16      LogisticRegression       0.25                   0.20  0.843711\n",
       "17  DecisionTreeClassifier       0.25                   0.20  0.943143\n",
       "18  RandomForestClassifier       0.25                   0.20  0.944413\n",
       "19           MLPClassifier       0.25                   0.20  0.943884\n",
       "20      LogisticRegression       0.30                   0.20  0.843598\n",
       "21  DecisionTreeClassifier       0.30                   0.20  0.942908\n",
       "22  RandomForestClassifier       0.30                   0.20  0.944380\n",
       "23           MLPClassifier       0.30                   0.20  0.943667\n",
       "24      LogisticRegression       0.20                   0.25  0.844794\n",
       "25  DecisionTreeClassifier       0.20                   0.25  0.943286\n",
       "26  RandomForestClassifier       0.20                   0.25  0.944010\n",
       "27           MLPClassifier       0.20                   0.25  0.943346\n",
       "28      LogisticRegression       0.25                   0.25  0.844341\n",
       "29  DecisionTreeClassifier       0.25                   0.25  0.943162\n",
       "30  RandomForestClassifier       0.25                   0.25  0.943833\n",
       "31           MLPClassifier       0.25                   0.25  0.943194\n",
       "32      LogisticRegression       0.30                   0.25  0.844294\n",
       "33  DecisionTreeClassifier       0.30                   0.25  0.942847\n",
       "34  RandomForestClassifier       0.30                   0.25  0.943269\n",
       "35           MLPClassifier       0.30                   0.25  0.943404\n",
       "36      LogisticRegression       0.20                   0.30  0.848467\n",
       "37  DecisionTreeClassifier       0.20                   0.30  0.942978\n",
       "38  RandomForestClassifier       0.20                   0.30  0.942277\n",
       "39           MLPClassifier       0.20                   0.30  0.942985\n",
       "40      LogisticRegression       0.25                   0.30  0.848077\n",
       "41  DecisionTreeClassifier       0.25                   0.30  0.942997\n",
       "42  RandomForestClassifier       0.25                   0.30  0.941953\n",
       "43           MLPClassifier       0.25                   0.30  0.942538\n",
       "44      LogisticRegression       0.30                   0.30  0.847982\n",
       "45  DecisionTreeClassifier       0.30                   0.30  0.942512\n",
       "46  RandomForestClassifier       0.30                   0.30  0.941570\n",
       "47           MLPClassifier       0.30                   0.30  0.942652"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the results to a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Save as JSON\n",
    "results_df.to_json(\"model_results.json\", orient=\"records\", indent=4)\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1a0fe7",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "In conclusion, we aimed to predict whether a tune was the ending of a song. First, we had to remake the dataset so that each tune was stored as a record. This allows us to use models on it. Then, we had to prepare data by choosing the attributes that contribute the most to making the predictions more accurate. Afterward, we had to deal with NaN values that were scattered everywhere using different strategies. \n",
    "\n",
    "We used four prediction models to make predictions. We had to play with hyperparameters of models to reduce the computation time while keeping the accuracy of predictions at a high level. `Random Forest` performed the best among all. On the other hand, `Logistic Regression` trains the fastest, although it has the lowest score among others (83.98%).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1d0414-3486-4c90-b39d-ac17f04da431",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
